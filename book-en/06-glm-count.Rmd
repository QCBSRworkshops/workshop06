# (PART\*) GLMs with count data {-}

# What can we do with count data?

To illustrate count data we will use a new dataset called faramea.

```{r, echo = TRUE, eval = FALSE}
faramea <- read.csv(‘faramea.csv’, header = TRUE)
```

In this dataset, the number of trees of the species *Faramea
occidentalis* was measured in 43 quadrats in Barro Colorada Island in
Panama. For each quadrat, environmental characteristics were also
recorded such as elevation or precipitation. Let's take a look at the
number of *Faramea occidentalis* found at each quadrat.

```{r, echo = TRUE, eval = FALSE}
hist(faramea$Faramea.occidentalis, breaks=seq(0,45,1), xlab=expression(paste("Number of ",
italic(Faramea~occidentalis))), ylab="Frequency", main="", col="grey")
```

![](images/plot_faramea_abd.png){.align-center width="500"}

We can see that there are only positive and integer values. Given these
specificities, the Poisson distribution, described above, seems to be
the perfect choice to model this data.

# Poisson GLMs

As we saw above, the Poisson distribution is particularly relevant to
model count data because it:

-   specifies the probably only for integer values
-   P(y\<0) = 0, hence the probability of any negative value is null
-   the mean-variance relationship allows for heterogeneity (e.g. when
    variance generally increases with the mean)

In this example, we want to test whether elevation (a continuous
explanatory variable) influences *Faramea occidentalis* abundance.
Hence, a Poisson GLM (i.e. a simple Poisson regression) seems to be a
good choice to model the number of *Faramea occidentalis* as a function
of elevation. Poisson GLMs are usually a good way to start modeling
count data.

![](images//plot_faramea_vs_elevation.png){.align-center width="400"}

**But what does a Poisson GLM do?**\
It assumes that the response variables y~i~ have been generated by a
Poisson distribution with mean and variance *µ*~i~.

Y~i~ ∼ Poisson(*µ*~i~)

with E(Y~i~) = Var(Y~i~) = *µ*~i~

Recall from above that *µ*~i~ can be replaced the systematic model\
Y~i~ \~ Poisson(β~0~ + β~1~X~i~)

A systematic part is used as a linear combination of unknown parameters
*β* representing the effects of different explanatory variables. **X**
is the covariate matrix (which does not include an intercept term in
this example). This systemtatic part is define as:

*β*~0~ + **X**~i~.*β*

The mean of the distribution *µ*~i~ is related to the systematic part
using a logarithm link function. As a result, the relationship between
the mean and the linear predictor is log-linear.

-   log(*µ*~i~) = *β*~0~ + **X**~i~.*β*

or

-   *µ*~i~ = exp(*β*~0~ + **X**~i~.*β*)

The Poisson distribution gives you the probability that a particular
Y~i~ value is observed for a given mean *µ*~i~ = exp(*β*~0~ +
**X**~i~.*β*). In this model, the unknown parameters are included in the
vector of regression coefficients *β* (plus the intercept *β*~0~) and
can be estimated using maximum-likelihood (ML) estimation.

Fitting a Poisson GLM in R requires only setting *family = poisson* in
the function glm(). By default the link function is log.

```{r, echo = TRUE, eval = FALSE}
glm.poisson = glm(Faramea.occidentalis~Elevation, data=faramea, family=poisson)
summary(glm.poisson)
```

The output is similar to a '**lm**' output (see workshop 4) and gives
you the parameter estimates which can also be retrieved using other
functions:

```{r, echo = TRUE, eval = FALSE}
# intercept
summary(glm.poisson)$coefficients[1,1]
# slope of elevation
summary(glm.poisson)$coefficients[2,1]
```

## The problem of overdispersion

An important aspect of the summary can be found in the last lines.

```{r, echo = TRUE, eval = FALSE}
summary(glm.poisson)
# Null deviance: 414.81  on 42  degrees of freedom
# Residual deviance: 388.12  on 41  degrees of freedom
```

Remember that ML estimation is used to estimate the parameters. In the
goodness-of-fit section we mentioned that the deviance was a ML
equivalent of the sum of squares in linear models. Here, the null
deviance and the residual deviance are equivalent to the total sum of
squares and the residual sum of squares respectively. The residual
deviance is defined as twice the difference between the log likelihood
of a model that provides a perfect fit to the data (a saturated model)
and the log likelihood of the model. If our model is correct the
asymptotic distribution of the residual deviance is approximated using
χ² distribution with *n*-*p*-1 degrees of freedom (computed as
*n*-*p*-1, where *n* is the number of observations and *p* the number of
covariates). This implies that residual deviance should be equal to the
residual degrees of freedom. In our example, the residual deviance
equals 388.12 while we have 41 (43-1-1) degrees of freedom. This former
is greater to the former by 9.5 times, the model is then
**overdispersed**.

**Overdispersion** As a consequence overdispersion can be computed for
any model using the parameter φ:

                          φ = residual deviance / residual degrees of freedom
    * φ < 1 indicates underdispersion
    * φ = 1 indicates no overdispersion
    * φ > 1 indicates overdispersion

Why does a Poisson GLM exhibit overdispersion? This arises when the
variance of the data is higher than expected from the Poisson
distribution. This frequently occurs when data includes many zeros
and/or many very high values. Looking back at the distribution of our
data (above) suggests that our data contains many zero preventing us to
use a Poisson GLM. Overdispersion may also result from missing
covariates, missing interaction terms or presence of strong outliers,
preventing us from using a Poisson GLM.

The Poisson distribution can account only partially for heterogeneity in
the data due to the mean variance relationship, but in some cases
variance increases even higher than the mean. Computing the mean and the
variance of our dataset suggests this is occurring:

```{r, echo = TRUE, eval = FALSE}
mean(faramea$Faramea.occidentalis)
var(faramea$Faramea.occidentalis)
```

In practice, Poissons GLM are useful for describing the mean *µ*~i~ but
underestimates the variance in the data, making all model-based tests
too liberal! There are two ways of dealing with overdispersion and will
be developed below:

-   correct for it by doing a **quasi-Poisson GLM**
-   choose another distribution such as the **negative binomial**

# quasi-Poisson GLMs

The principle behind a quasi-Poisson GLM is very simple; the
overdispersion parameter (φ) is added to the expected variance equation:

E(Y~i~) = *µ*~i~

Var(Y~i~) = φ.*µ*~i~

The systematic part and the link function remains the same. The
difference is that φ will first be estimated to correct the model.
Parameter Estimates will be the same but the standard errors of the
parameters are multiplied by √φ, in other terms, some marginally
significant p-values may no longer hold.

In R, The '**quasipoisson**' family object can be used to deal with
count data exhibiting overdispersion (the '**quasibinomial**' family
object can do the same for binomial data). The fitted φ value will be
returned in the summary of the GLM. There are two ways to perform this
GLM:

```{r, echo = TRUE, eval = FALSE}
# Option 1, fit a new quasi-Poisson GLM
glm.quasipoisson = glm(Faramea.occidentalis~Elevation, data=faramea, family=quasipoisson)
# Option 2, build from the previous model and update it:
glm.quasipoisson = update(glm.poisson,family=quasipoisson)
# output
summary(glm.quasipoisson)
```

If you look at the summary of the model you will see that φ is estimated
as 15.97. We then made a good choice by updating the model to account
for overdispersion. However if we look at P-values we can note that
elevation is no longer significant. Yet, 15.97 is quite a lot of
overdispersion, and in general quasi-Poisson GLMs will be favoured when
φ is included between 1 and 15 though these limits are arbitrary. When
overdispersion is higher than 15-20 we recommend moving to the negative
binomial. For the sake of pedagogy, we will consider that we are not
happy with this model to fit a final negative-binomial GLM to our data.

Two other points are important to keep in mind when using quasi-Poisson
GLMs and dealing with overdispersion:

-   **quasi-Poisson GLMs do not have AIC scores.** An important aspect
    is that quasi-Poisson GLMs do not correspond to models with fully
    specified likelihoods and rely on quasi-ML estimation (i.e.
    pseudolikelihood). One consequence is that quasi-Poisson GLMs do not
    have AIC scores for model comparisons. However, variants of AIC have
    been developed to deal with this situation (e.g. quasi-AIC).

```{=html}
<!-- -->
```
-   **Overdispersion affects model comparison.** Indeed overdispersion
    also influences the comparison of two nested models and has to be
    taken into account when φ is known. For instance, let's assume that
    we want to compare GLM1, with *p*~1~ parameters to GLM2, with *p*~2~
    parameters, such that GLM1 is nested within GLM2 and *p*~2~ \>
    *p*~1~. Model comparison is achieved based on a generalized
    likelihood ratio test, which can be written as a function of the
    difference of deviances between the two GLMs, D~1~ and D~2~
    respectively. If Overdispersion is known, deviances have to be
    scaled (i.e. corrected) accordingly as D\* = D/φ. The final test
    will be based on the criterion D~1~\* - D\*~2~ which is assumed to
    follow a χ² distribution with *p*~2~-*p*~1~ degrees of freedom when
    GLM1 is correct.
-   In some cases φ is not known. For instance, this occurs when you run
    a GLM with a normal error distribution. In that case, φ can be
    estimated *a posteriori* using the residual deviance of the larger
    model so the criterion becomes
    \[(D~1~-D~2~)/(*p*~2~-*p*~1~)\]/\[D~2~/(*n*-*p*~2~)\] and is assumed
    to follow a F distribution with *p*~2~-*p*~1~ and n-*p*~2~ degrees
    of freedom.

# Negative binomial GLMs

GLM with a negative binomial (NB) distribution are favored when
overdispersion is extreme. The NB distribution contains an additional
parameter *k*, particularly handy for count data containing a
preponderance of zeros. Before we go into R stuff, we should see what
lies behind a negative binomial GLM. A NB distribution is actually a
combination of two distributions: a Poisson distribution and a gamma
distribution. The NB distribution first assumes that a discrete random
variable is Poisson distributed but its mean, *µ* is assumed to follow a
gamma distribution. The mixture between the Poisson and gamma
distributions can be simplified into a density function specific to the
NB which has two parameters *µ* and *k*.

Y \~ NB(*µ*, *k*)

E(Y) = *µ* and Var(Y) = *µ* + *µ*²*/k*

Here, we can see how overdispersion will be accounted for by NB
distribution in GLMs. The second term of the variance determines the
amount of overdispersion. In fact, it is indirectly determined by *k*,
where *k* is also called the dispersion parameter. If *k* is large
(relative to *μ*²), the second term, *µ*²*/k* approximates 0, and the
variance of Y is *μ*. In such cases the NB converges to the Poisson
distribution and you might as well use a Poisson distribution. The
smaller *k*, the larger the overdispersion. Just like with others GLMs,
a NB GLM is specified following the fundamental three steps. It first
assumes that Y~i~ is negative binomial distributed with mean *μ*~i~ and
parameter *k*.

Y~i~ ∼ NB(*µ*~i~, *k*)

E(Y~i~) = *µ*~i~ and Var(Y~i~) = *µ*~i~ + *µ*~i~²*/k*

The two last steps define the systematic part and the link function
between the mean of Yi and the predictor function. In NB GLMs the link
function is logarithmic ensuring that fitted values are always positive.

-   log(*µ*~i~) = *β*~0~ + **X**~i~.*β*

or

-   *µ*~i~ = exp(*β*~0~ + **X**~i~.*β*)

NB is not in the glm() function so you need to install and load the MASS
library. You do not remember if you already installed this package? No
problem, you can use the following function:

```{r, echo = TRUE, eval = FALSE}
ifelse(length(which(installed.packages() == "MASS")) == 0,
      {print("MASS not installed. Installing... "); install.packages("MASS")},
      print("MASS already installed"))
```

Alternatively, if you know that this package is not installed you can
directly use the command

```{r, echo = TRUE, eval = FALSE}
install.packages("MASS")
```

and remember to load the package

```{r, echo = TRUE, eval = FALSE}
library("MASS")
```

The negative binomial GLM can be build using the glm.nb() function:

```{r, echo = TRUE, eval = FALSE}
glm.negbin = glm.nb(Faramea.occidentalis~Elevation, data=faramea)
summary(glm.negbin)
```

The summary is similar to other GLMs summaries (e.g. Poisson GLMs),
though we now have a parameter theta, which stands for parameter *k* in
the variance of the NB distribution. Its standard error is also
provided, but care is needed with its use as the interval is not
symmetric and we are testing on the boundary.

## Plotting the final GLM to the data

The NB GLMs appear to be the best fit to our data. We can plot the
relationship between the abundance of Faramea occidentalis and
elevation.

```{r, echo = TRUE, eval = FALSE}
# plot the observed data
plot(faramea$Elevation, faramea$Faramea.occidentalis, xlab="Elevation (m)", ylab=expression(paste("Number of", "  ", italic(Faramea~occidentalis))), pch=16, col=rgb(4,139,154,150,maxColorValue=255))

# pull values for intercept and beta from the summary and put them in the exponential equation
curve(exp(summary(glm.negbin)$coefficients[1,1]+summary(glm.negbin)$coefficients[2,1]*x),from=range(faramea$Elevation)[1],to=range(faramea$Elevation)[2],add=T, lwd=2, col="orangered")

# pull the standard error as well to plot the equations for confidence envelope
curve(exp(summary(glm.negbin)$coefficients[1,1]+1.96*summary(glm.negbin)$coefficients[1,2]+summary(glm.negbin)$coefficients[2,1]*x+1.96*summary(glm.negbin)$coefficients[2,2]),from=range(faramea$Elevation)[1],to=range(faramea$Elevation)[2],add=T,lty=2, col="orangered")
curve(exp(summary(glm.negbin)$coefficients[1,1]-1.96*summary(glm.negbin)$coefficients[1,2]+summary(glm.negbin)$coefficients[2,1]*x-1.96*summary(glm.negbin)$coefficients[2,2]),from=range(faramea$Elevation)[1],to=range(faramea$Elevation)[2],add=T,lty=2, col="orangered")
```

![](images/nb_glm_fit_to_faramea.png){.align-center width="450"}

We can see that the number of *Faramea occidentalis* significantly
decreases with elevation. However, the confidence envelope of the NB
model is large at low elevation.

# Conclusion on GLMs with count data

All the GLMs introduced (Poisson, quasi-Poisson and NB) to model count
data use the same log-linear mean function (log(*µ*) = **X**.*β*), but
make different assumptions about the remaining likelihood. Quasi-Poisson
and NB are favored to deal with overdispersion. However, in some cases
the data may contains too many zeros and zero-augmented models can be
useful as they extend the mean function by modifying (typically,
increasing) the likelihood of zero counts (e.g. zero-inflated Poisson
\[ZIP\]).