<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 8 Binomial GLMs (Bernouilli) | Workshop 6: Generalized linear models</title>
  <meta name="description" content="Generalized linear models in R" />
  <meta name="generator" content="bookdown 0.21 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 8 Binomial GLMs (Bernouilli) | Workshop 6: Generalized linear models" />
  <meta property="og:type" content="book" />
  <meta property="og:url" content="https://github.com/qcbsRworkshops/" />
  <meta property="og:image" content="https://github.com/qcbsRworkshops/assets/images/logo/csbq_logo_accueil.png" />
  <meta property="og:description" content="Generalized linear models in R" />
  <meta name="github-repo" content="qcbsRworkshops/workshop06" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 8 Binomial GLMs (Bernouilli) | Workshop 6: Generalized linear models" />
  
  <meta name="twitter:description" content="Generalized linear models in R" />
  <meta name="twitter:image" content="https://github.com/qcbsRworkshops/assets/images/logo/csbq_logo_accueil.png" />

<meta name="author" content="Developed and maintained by the contributors of the QCBS R Workshop Series" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  <link rel="shortcut icon" href="assets/images/favicon.ico" type="image/x-icon" />
<link rel="prev" href="binary-variables.html"/>
<link rel="next" href="binomial-glms.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<script src="libs/accessible-code-block-0.0.1/empty-anchor.js"></script>


<style type="text/css">
code.sourceCode > span { display: inline-block; line-height: 1.25; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  background-color: #f8f8f8; }
@media screen {
code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ef2929; } /* Alert */
code span.an { color: #8f5902; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #c4a000; } /* Attribute */
code span.bn { color: #0000cf; } /* BaseN */
code span.cf { color: #204a87; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4e9a06; } /* Char */
code span.cn { color: #000000; } /* Constant */
code span.co { color: #8f5902; font-style: italic; } /* Comment */
code span.cv { color: #8f5902; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #8f5902; font-weight: bold; font-style: italic; } /* Documentation */
code span.dt { color: #204a87; } /* DataType */
code span.dv { color: #0000cf; } /* DecVal */
code span.er { color: #a40000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #0000cf; } /* Float */
code span.fu { color: #000000; } /* Function */
code span.im { } /* Import */
code span.in { color: #8f5902; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #204a87; font-weight: bold; } /* Keyword */
code span.op { color: #ce5c00; font-weight: bold; } /* Operator */
code span.ot { color: #8f5902; } /* Other */
code span.pp { color: #8f5902; font-style: italic; } /* Preprocessor */
code span.sc { color: #000000; } /* SpecialChar */
code span.ss { color: #4e9a06; } /* SpecialString */
code span.st { color: #4e9a06; } /* String */
code span.va { color: #000000; } /* Variable */
code span.vs { color: #4e9a06; } /* VerbatimString */
code span.wa { color: #8f5902; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="assets/qcbs-style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="toc-logo"><a href="./"><img src="assets/images/csbq_logo_gray_accueil.png"></a></li>
<link rel="icon" type="image/png" href="assets/images/favicon.ico"/>

<li class="divider"></li>
<li class="part"><span><b>QCBS R Workshop Series</b></span></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a><ul>
<li class="chapter" data-level="0.1" data-path="index.html"><a href="index.html#code-of-conduct"><i class="fa fa-check"></i><b>0.1</b> Code of conduct</a><ul>
<li class="chapter" data-level="0.1.1" data-path="index.html"><a href="index.html#expected-behaviour"><i class="fa fa-check"></i><b>0.1.1</b> Expected behaviour</a></li>
<li class="chapter" data-level="0.1.2" data-path="index.html"><a href="index.html#unacceptable-behaviour"><i class="fa fa-check"></i><b>0.1.2</b> Unacceptable behaviour</a></li>
</ul></li>
<li class="chapter" data-level="0.2" data-path="index.html"><a href="index.html#contributors"><i class="fa fa-check"></i><b>0.2</b> Contributors</a></li>
<li class="chapter" data-level="0.3" data-path="index.html"><a href="index.html#contributing"><i class="fa fa-check"></i><b>0.3</b> Contributing</a></li>
</ul></li>
<li class="part"><span><b>Generalized linear models in <code>R</code></b></span></li>
<li class="chapter" data-level="1" data-path="learning-objectives.html"><a href="learning-objectives.html"><i class="fa fa-check"></i><b>1</b> Learning objectives</a></li>
<li class="chapter" data-level="2" data-path="preparing-for-the-workshop.html"><a href="preparing-for-the-workshop.html"><i class="fa fa-check"></i><b>2</b> Preparing for the workshop</a></li>
<li class="chapter" data-level="3" data-path="reviewing-linear-models.html"><a href="reviewing-linear-models.html"><i class="fa fa-check"></i><b>3</b> Reviewing linear models</a><ul>
<li class="chapter" data-level="3.1" data-path="reviewing-linear-models.html"><a href="reviewing-linear-models.html#general-linear-models"><i class="fa fa-check"></i><b>3.1</b> General linear models</a><ul>
<li class="chapter" data-level="3.1.1" data-path="reviewing-linear-models.html"><a href="reviewing-linear-models.html#definition"><i class="fa fa-check"></i><b>3.1.1</b> Definition</a></li>
<li class="chapter" data-level="3.1.2" data-path="reviewing-linear-models.html"><a href="reviewing-linear-models.html#assumptions"><i class="fa fa-check"></i><b>3.1.2</b> Assumptions</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="an-example-with-general-linear-models.html"><a href="an-example-with-general-linear-models.html"><i class="fa fa-check"></i><b>4</b> An example with general linear models</a><ul>
<li class="chapter" data-level="4.1" data-path="an-example-with-general-linear-models.html"><a href="an-example-with-general-linear-models.html#recalling-linear-models-assumptions"><i class="fa fa-check"></i><b>4.1</b> Recalling linear models: assumptions</a><ul>
<li class="chapter" data-level="4.1.1" data-path="an-example-with-general-linear-models.html"><a href="an-example-with-general-linear-models.html#model-prediction"><i class="fa fa-check"></i><b>4.1.1</b> Model prediction</a></li>
<li class="chapter" data-level="4.1.2" data-path="an-example-with-general-linear-models.html"><a href="an-example-with-general-linear-models.html#so-what-do-we-do-now-transform-our-data"><i class="fa fa-check"></i><b>4.1.2</b> So, what do we do now? Transform our data?</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="the-distributions-of-biological-data.html"><a href="the-distributions-of-biological-data.html"><i class="fa fa-check"></i><b>5</b> The distributions of biological data</a></li>
<li class="chapter" data-level="6" data-path="generalized-linear-models.html"><a href="generalized-linear-models.html"><i class="fa fa-check"></i><b>6</b> Generalized Linear Models</a></li>
<li class="part"><span><b>GLMs with binary data</b></span></li>
<li class="chapter" data-level="7" data-path="binary-variables.html"><a href="binary-variables.html"><i class="fa fa-check"></i><b>7</b> Binary variables</a><ul>
<li class="chapter" data-level="7.1" data-path="binary-variables.html"><a href="binary-variables.html#glm-with-binomial-data-logit-link"><i class="fa fa-check"></i><b>7.1</b> GLM with binomial data: logit link</a></li>
<li class="chapter" data-level="7.2" data-path="binary-variables.html"><a href="binary-variables.html#exercise-1"><i class="fa fa-check"></i><b>7.2</b> Exercise 1</a></li>
<li class="chapter" data-level="7.3" data-path="binary-variables.html"><a href="binary-variables.html#challenge-1"><i class="fa fa-check"></i><b>7.3</b> Challenge 1</a><ul>
<li class="chapter" data-level="7.3.1" data-path="binary-variables.html"><a href="binary-variables.html#challenge-1-solution"><i class="fa fa-check"></i><b>7.3.1</b> Challenge 1: Solution</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="binomial-glms-bernouilli.html"><a href="binomial-glms-bernouilli.html"><i class="fa fa-check"></i><b>8</b> Binomial GLMs (Bernouilli)</a><ul>
<li class="chapter" data-level="8.1" data-path="binomial-glms-bernouilli.html"><a href="binomial-glms-bernouilli.html#the-link-function"><i class="fa fa-check"></i><b>8.1</b> The link function</a></li>
<li class="chapter" data-level="8.2" data-path="binomial-glms-bernouilli.html"><a href="binomial-glms-bernouilli.html#interpreting-the-output-of-a-logistic-regression"><i class="fa fa-check"></i><b>8.2</b> Interpreting the output of a logistic regression</a></li>
<li class="chapter" data-level="8.3" data-path="binomial-glms-bernouilli.html"><a href="binomial-glms-bernouilli.html#predictive-power-and-goodness-of-fit"><i class="fa fa-check"></i><b>8.3</b> Predictive power and goodness-of-fit</a><ul>
<li class="chapter" data-level="8.3.1" data-path="binomial-glms-bernouilli.html"><a href="binomial-glms-bernouilli.html#challenge-2"><i class="fa fa-check"></i><b>8.3.1</b> Challenge 2</a></li>
<li class="chapter" data-level="8.3.2" data-path="binomial-glms-bernouilli.html"><a href="binomial-glms-bernouilli.html#challenge-2-solution"><i class="fa fa-check"></i><b>8.3.2</b> Challenge 2: Solution</a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="binomial-glms-bernouilli.html"><a href="binomial-glms-bernouilli.html#plotting-results"><i class="fa fa-check"></i><b>8.4</b> Plotting results</a></li>
</ul></li>
<li class="part"><span><b>GLMs with proportion data</b></span></li>
<li class="chapter" data-level="9" data-path="binomial-glms.html"><a href="binomial-glms.html"><i class="fa fa-check"></i><b>9</b> Binomial GLMS</a></li>
<li class="part"><span><b>GLMs with count data</b></span></li>
<li class="chapter" data-level="10" data-path="what-can-we-do-with-count-data.html"><a href="what-can-we-do-with-count-data.html"><i class="fa fa-check"></i><b>10</b> What can we do with count data?</a></li>
<li class="chapter" data-level="11" data-path="poisson-glms.html"><a href="poisson-glms.html"><i class="fa fa-check"></i><b>11</b> Poisson GLMs</a><ul>
<li class="chapter" data-level="11.1" data-path="poisson-glms.html"><a href="poisson-glms.html#the-problem-of-overdispersion"><i class="fa fa-check"></i><b>11.1</b> The problem of overdispersion</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="quasi-poisson-glms.html"><a href="quasi-poisson-glms.html"><i class="fa fa-check"></i><b>12</b> Quasi-Poisson GLMs</a></li>
<li class="chapter" data-level="13" data-path="negative-binomial-glms.html"><a href="negative-binomial-glms.html"><i class="fa fa-check"></i><b>13</b> Negative binomial GLMs</a><ul>
<li class="chapter" data-level="13.1" data-path="negative-binomial-glms.html"><a href="negative-binomial-glms.html#plotting-the-final-glm-to-the-data"><i class="fa fa-check"></i><b>13.1</b> Plotting the final GLM to the data</a><ul>
<li class="chapter" data-level="13.1.1" data-path="negative-binomial-glms.html"><a href="negative-binomial-glms.html#challenge-3"><i class="fa fa-check"></i><b>13.1.1</b> Challenge 3</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="14" data-path="conclusion-on-glms-with-count-data.html"><a href="conclusion-on-glms-with-count-data.html"><i class="fa fa-check"></i><b>14</b> Conclusion on GLMs with count data</a></li>
<li class="part"><span><b>Other distributions</b></span></li>
<li class="chapter" data-level="15" data-path="other-distributions.html"><a href="other-distributions.html"><i class="fa fa-check"></i><b>15</b> Other distributions</a></li>
<li class="part"><span><b>Additional GLM resources</b></span></li>
<li class="chapter" data-level="16" data-path="summary.html"><a href="summary.html"><i class="fa fa-check"></i><b>16</b> Summary</a></li>
<li class="chapter" data-level="17" data-path="additional-resources.html"><a href="additional-resources.html"><i class="fa fa-check"></i><b>17</b> Additional resources</a></li>
<li class="chapter" data-level="18" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i><b>18</b> References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/qcbsRworkshops" target="blank">QCBS R Workshop Series</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Workshop 6: Generalized linear models</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<!------------------------ Hero Image Container --------------------------> 

<head>
  <meta name="viewport" content="width=device-width,minimum-scale=1.0,maximum-scale=10.0,initial-scale=1.0">
  <script src="https://kit.fontawesome.com/6a26f47516.js"></script>
  <script src="assets/qcbs-hideOutput.js"></script>
  <link href="assets/qcbs-style.css" rel="stylesheet">
</head>



<div class="hero-image-container"> 
  <img class= "hero-image" src="assets/images/jean-philippe-delberghe-75xPHEQBmvA-unsplash_hero_image.jpg">
</div>
<div id="binomial-glms-bernouilli" class="section level1">
<h1><span class="header-section-number">Chapter 8</span> Binomial GLMs (Bernouilli)</h1>
<p>We’ve already seen that binary variables are not normally distributed (<em>i.e.</em>
we see a peak at 0 and a peak at 1 and nothing in between). Like we have
seen in the previous section, the Bernoulli distribution is well suited
for binary response variables. The mean of this distribution is the
probability <span class="math inline">\(p\)</span> of observing an outcome and the variance is <span class="math inline">\(p/(1 - p)\)</span>. The <span class="math inline">\((1 - p)\)</span> term represents the probability of <strong>not</strong> observing
an outcome. In <code>R</code>, we specify the distribution with the <code>family</code>
argument. For the logistic regression, we code it as:
<code>family="binomial"</code>. Remember that the Bernoulli distribution is a
special case of the binomial distribution when the number of repetitions
is 1: R will “understand” that it is a Bernoulli distribution.</p>
<p>When predicting the probability of observing some phenomenon <span class="math inline">\(Y\)</span>, which is
a binary variable, the expected values should be bound between 0 and 1:
that’s the range of a probability value! If we use a basic linear model
to relate a binary response variable to various explanatory variables,
we might obtain fitted values outside of the <span class="math inline">\([0,1]\)</span> range, which is
nonsensical.</p>
<p>The following example will help you understand why a basic
linear model is inappropriate here. The next subsection will show you
how to avoid this problem with a link function. Briefly, a link function
is used to linearize the relationship between predicted values of the
response variable and the linear predictor (see next subsection).</p>
<div class="sourceCode" id="cb60"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb60-1"><a href="binomial-glms-bernouilli.html#cb60-1"></a>model.lm &lt;-<span class="st"> </span><span class="kw">lm</span>(pa <span class="op">~</span><span class="st"> </span>WatrCont <span class="op">+</span><span class="st"> </span>Topo, <span class="dt">data =</span> mites)</span>
<span id="cb60-2"><a href="binomial-glms-bernouilli.html#cb60-2"></a><span class="co"># Let&#39;s get the expected values for the response variable.</span></span>
<span id="cb60-3"><a href="binomial-glms-bernouilli.html#cb60-3"></a><span class="kw">fitted</span>(model.lm)</span></code></pre></div>
<pre><code>##           1           2           3           4           5           6 
##  0.66647889  0.53692818  0.63347146  0.65064083  0.88992555  0.72554642 
##           7           8           9          10          11          12 
##  0.62243838  0.44918156  0.38197312  0.86452345  0.65216882  0.58115232 
##          13          14          15          16          17          18 
##  0.82937368  0.49091140  0.32085505  0.70975427  0.74788803  0.77927339 
##          19          20          21          22          23          24 
##  0.27006616  0.97936848  0.92066821  0.91783725  0.59213949  0.75609015 
##          25          26          27          28          29          30 
##  0.40830867  0.45469271  0.97998058  0.65973050  0.70784146  0.24024164 
##          31          32          33          34          35          36 
##  0.44598561  0.42241754  0.26475620  0.29565189  0.41782680  0.21776232 
##          37          38          39          40          41          42 
##  0.25508504  0.04877715 -0.20118869  0.24807651  0.14103573  0.26617933 
##          43          44          45          46          47          48 
## -0.03165263 -0.22623884  0.03336756  0.16659086  0.36168204  0.08179987 
##          49          50          51          52          53          54 
##  0.30060989  0.19286520  0.14544285 -0.04279283  0.22290395  0.04560953 
##          55          56          57          58          59          60 
##  0.17240580  0.04198285 -0.08121733  0.31664687 -0.14695674  0.14463181 
##          61          62          63          64          65          66 
## -0.10106464 -0.11390341  0.11942865  0.19182463  0.46870977  0.06957320 
##          67          68          69          70 
## -0.40803217 -0.04559318  0.46895461  0.41060630</code></pre>
<div class="sourceCode" id="cb62"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb62-1"><a href="binomial-glms-bernouilli.html#cb62-1"></a><span class="co"># Some values are lower than 0, which does not make sense for a</span></span>
<span id="cb62-2"><a href="binomial-glms-bernouilli.html#cb62-2"></a><span class="co"># logistic regression. Let’s try the same model with a binomial</span></span>
<span id="cb62-3"><a href="binomial-glms-bernouilli.html#cb62-3"></a><span class="co"># distribution instead.</span></span>
<span id="cb62-4"><a href="binomial-glms-bernouilli.html#cb62-4"></a></span>
<span id="cb62-5"><a href="binomial-glms-bernouilli.html#cb62-5"></a>model.glm &lt;-<span class="st"> </span><span class="kw">glm</span>(pa <span class="op">~</span><span class="st"> </span>WatrCont <span class="op">+</span><span class="st"> </span>Topo,</span>
<span id="cb62-6"><a href="binomial-glms-bernouilli.html#cb62-6"></a>  <span class="dt">data =</span> mites,</span>
<span id="cb62-7"><a href="binomial-glms-bernouilli.html#cb62-7"></a>  <span class="dt">family =</span> <span class="st">&quot;binomial&quot;</span>)</span>
<span id="cb62-8"><a href="binomial-glms-bernouilli.html#cb62-8"></a>  <span class="co"># Notice the &quot;family&quot; argument to specify the distribution.</span></span>
<span id="cb62-9"><a href="binomial-glms-bernouilli.html#cb62-9"></a><span class="kw">fitted</span>(model.glm)</span></code></pre></div>
<pre><code>##            1            2            3            4            5            6 
## 0.7346594257 0.4206031345 0.6631394056 0.7015590344 0.9653549812 0.8359993456 
##            7            8            9           10           11           12 
## 0.6372174958 0.5611742138 0.3897035615 0.9554194818 0.9124133201 0.5341181089 
##           13           14           15           16           17           18 
## 0.9371232991 0.6630994614 0.2534848511 0.8123833970 0.8652527310 0.8987976705 
##           19           20           21           22           23           24 
## 0.1672936363 0.9859583431 0.9745439489 0.9738080708 0.5622303983 0.8748321042 
##           25           26           27           28           29           30 
## 0.4560079466 0.2368433083 0.9860456411 0.7208455080 0.8093521595 0.1286310583 
##           31           32           33           34           35           36 
## 0.2209673461 0.4923424344 0.1597888373 0.2074205123 0.4804923276 0.1047615219 
##           37           38           39           40           41           42 
## 0.1468234813 0.0200046339 0.0015397957 0.1379815251 0.0502950337 0.1617730592 
##           43           44           45           46           47           48 
## 0.0088128566 0.0011890438 0.0171102995 0.0645145152 0.3411366744 0.0279131027 
##           49           50           51           52           53           54 
## 0.2159692960 0.0829690298 0.0525153673 0.0078621097 0.1098500760 0.0193729227 
##           55           56           57           58           59           60 
## 0.0682372458 0.0186736500 0.0052993359 0.2453448032 0.0026936317 0.0520999273 
##           61           62           63           64           65           66 
## 0.0043209522 0.0037861341 0.0406398167 0.0821545812 0.2640115440 0.0246819529 
##           67           68           69           70 
## 0.0001818862 0.0076395774 0.2645034420 0.1644306746</code></pre>
<div class="sourceCode" id="cb64"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb64-1"><a href="binomial-glms-bernouilli.html#cb64-1"></a><span class="co"># All values are bound between 0 and 1.</span></span></code></pre></div>
<div id="the-link-function" class="section level2">
<h2><span class="header-section-number">8.1</span> The link function</h2>
<p>To move away from the traditional linear model and to avoid its biases,
we need to specify two things when using a logistic regression: a
distribution for the residuals of the model and a link function for the
expected values. We already presented the Bernoulli distribution in the
previous section so let’s have a look at what the link function is.</p>
<p>In the case of a simple linear model of a normally distributed
continuous response variable, the following equation gives the expected
values:</p>
<p><span class="math display">\[ \mu = X\beta \]</span></p>
<p>where <span class="math inline">\(\mu\)</span> is the expected value of the response variable, <span class="math inline">\(X\)</span> is the
model matrix (<em>i.e.</em> representing your data) and <span class="math inline">\(\beta\)</span> corresponds to the
parameters we estimate from the data (<em>i.e.</em> the intercept and the
slope). The right-hand side of this equation is called the linear
predictor. In mathematical terms, it is the matrix product of the model
matrix <span class="math inline">\(X\)</span> of a statistical model and the vector of estimated parameters
<span class="math inline">\(\beta\)</span>. Let’s have a look at this in <code>R</code>:</p>
<div class="sourceCode" id="cb65"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb65-1"><a href="binomial-glms-bernouilli.html#cb65-1"></a><span class="co"># Load the CO2 dataset. We used it during workshop 4!</span></span>
<span id="cb65-2"><a href="binomial-glms-bernouilli.html#cb65-2"></a><span class="kw">data</span>(CO2)</span>
<span id="cb65-3"><a href="binomial-glms-bernouilli.html#cb65-3"></a><span class="kw">head</span>(CO2)</span></code></pre></div>
<pre><code>##   Plant   Type  Treatment conc uptake
## 1   Qn1 Quebec nonchilled   95   16.0
## 2   Qn1 Quebec nonchilled  175   30.4
## 3   Qn1 Quebec nonchilled  250   34.8
## 4   Qn1 Quebec nonchilled  350   37.2
## 5   Qn1 Quebec nonchilled  500   35.3
## 6   Qn1 Quebec nonchilled  675   39.2</code></pre>
<p>Build a linear model of plant CO2 uptake as a function of CO2 ambient concentration.</p>
<div class="sourceCode" id="cb67"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb67-1"><a href="binomial-glms-bernouilli.html#cb67-1"></a><span class="co"># Build the model</span></span>
<span id="cb67-2"><a href="binomial-glms-bernouilli.html#cb67-2"></a>model.CO2 &lt;-<span class="st"> </span><span class="kw">lm</span>(uptake <span class="op">~</span><span class="st"> </span>conc, <span class="dt">data =</span> CO2)</span>
<span id="cb67-3"><a href="binomial-glms-bernouilli.html#cb67-3"></a></span>
<span id="cb67-4"><a href="binomial-glms-bernouilli.html#cb67-4"></a><span class="co"># Extract the design matrix of the model</span></span>
<span id="cb67-5"><a href="binomial-glms-bernouilli.html#cb67-5"></a>X &lt;-<span class="st"> </span><span class="kw">model.matrix</span>(model.CO2)</span>
<span id="cb67-6"><a href="binomial-glms-bernouilli.html#cb67-6"></a><span class="co"># And the estimated coefficients.</span></span>
<span id="cb67-7"><a href="binomial-glms-bernouilli.html#cb67-7"></a>B &lt;-<span class="st"> </span>model.CO2<span class="op">$</span>coefficients</span>
<span id="cb67-8"><a href="binomial-glms-bernouilli.html#cb67-8"></a></span>
<span id="cb67-9"><a href="binomial-glms-bernouilli.html#cb67-9"></a><span class="co"># Let’s multiply both X and B matrices to obtain the linear predictor.</span></span>
<span id="cb67-10"><a href="binomial-glms-bernouilli.html#cb67-10"></a><span class="co"># The &quot;%*%&quot; symbol indicates that it is a matrix product.</span></span>
<span id="cb67-11"><a href="binomial-glms-bernouilli.html#cb67-11"></a>XB &lt;-<span class="st"> </span>X <span class="op">%*%</span><span class="st"> </span>B</span>
<span id="cb67-12"><a href="binomial-glms-bernouilli.html#cb67-12"></a></span>
<span id="cb67-13"><a href="binomial-glms-bernouilli.html#cb67-13"></a><span class="co"># Compare the values of XB to the values obtained with the predict() function.</span></span>
<span id="cb67-14"><a href="binomial-glms-bernouilli.html#cb67-14"></a><span class="co"># All statements should be TRUE.</span></span>
<span id="cb67-15"><a href="binomial-glms-bernouilli.html#cb67-15"></a></span>
<span id="cb67-16"><a href="binomial-glms-bernouilli.html#cb67-16"></a><span class="co"># We use the round() function so that all elements have 5 digits.</span></span>
<span id="cb67-17"><a href="binomial-glms-bernouilli.html#cb67-17"></a><span class="kw">round</span>(<span class="kw">fitted</span>(model.CO2), <span class="dt">digits =</span> <span class="dv">5</span>) <span class="op">==</span><span class="st"> </span><span class="kw">round</span>(XB, <span class="dt">digits =</span> <span class="dv">5</span>)</span></code></pre></div>
<pre><code>##    [,1]
## 1  TRUE
## 2  TRUE
## 3  TRUE
## 4  TRUE
## 5  TRUE
## 6  TRUE
## 7  TRUE
## 8  TRUE
## 9  TRUE
....</code></pre>
<p>When using a simple linear model with a normally distributed response
variable, the linear predictor is directly equal to the expected values
of the model. But, what if our response variable is not normally
distributed? If that is the case, we have to use a transformation on the
expected values, <em>i.e.</em> a link function. A link function can be
understood as a transformation of the expected values so that it can be
<strong>linearly related</strong> to the linear predictor:</p>
<p><span class="math display">\[g(\mu) = X\beta\]</span></p>
<p>where <span class="math inline">\(g(\mu)\)</span> is the link function for the expected values. This allows
us to relax the normality assumption. In the case of a binary response
variable, the link function is called the logit function and is given
by:</p>
<p><span class="math display">\[logit(\mu) = log (\mu / 1-\mu) = X\beta\]</span></p>
<p>where <span class="math inline">\(\mu\)</span> represents expected values (<em>i.e.</em> the probability that Y = 1
because we observed the presence of a species, disease, success, or some
other event). The ratio <span class="math inline">\(\mu / 1-\mu\)</span> represents the odds that some
outcome occured and it transforms the expected values into continuous
values from 0 to infinity. If we have a 0.8 probability of observing
species X, then our odds are 4 times more likely to observe the species
than to not observe it: 0.8/(1-0.8) = 4. The log transformation, called
the log odds, allows values to be spread across -infinity to infinity.
Hence, the logit function took the expected values of a model and
transformed them into continuous values without boundaries. The expected
values can now be directly related to a linear predictor. This is why we
still call this model a generalized <strong>linear</strong> model even though the
plot of our response variable as a function of some explanatory variable
doesn’t look like a “straight line”!</p>
<p>Let’s build a regression model of the presence/absence of a mite species (Galumna sp.) as a function of water content and topography. To do this, we need to use the <code>glm()</code> function and specify the <code>family</code> argument.</p>
<div class="sourceCode" id="cb69"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb69-1"><a href="binomial-glms-bernouilli.html#cb69-1"></a>logit.reg &lt;-<span class="st"> </span><span class="kw">glm</span>(pa <span class="op">~</span><span class="st"> </span>WatrCont <span class="op">+</span><span class="st"> </span>Topo,</span>
<span id="cb69-2"><a href="binomial-glms-bernouilli.html#cb69-2"></a>  <span class="dt">data =</span> mites,</span>
<span id="cb69-3"><a href="binomial-glms-bernouilli.html#cb69-3"></a>  <span class="dt">family =</span> <span class="kw">binomial</span>(<span class="dt">link =</span> <span class="st">&quot;logit&quot;</span>))</span>
<span id="cb69-4"><a href="binomial-glms-bernouilli.html#cb69-4"></a></span>
<span id="cb69-5"><a href="binomial-glms-bernouilli.html#cb69-5"></a><span class="co"># The logit function is the default for the binomial distribution,</span></span>
<span id="cb69-6"><a href="binomial-glms-bernouilli.html#cb69-6"></a><span class="co"># so it is not necessary to include it in the &quot;family&quot; argument:</span></span>
<span id="cb69-7"><a href="binomial-glms-bernouilli.html#cb69-7"></a>logit.reg &lt;-<span class="st"> </span><span class="kw">glm</span>(pa <span class="op">~</span><span class="st"> </span>WatrCont <span class="op">+</span><span class="st"> </span>Topo,</span>
<span id="cb69-8"><a href="binomial-glms-bernouilli.html#cb69-8"></a>  <span class="dt">data =</span> mites,</span>
<span id="cb69-9"><a href="binomial-glms-bernouilli.html#cb69-9"></a>  <span class="dt">family =</span> binomial)</span>
<span id="cb69-10"><a href="binomial-glms-bernouilli.html#cb69-10"></a><span class="kw">summary</span>(logit.reg)</span></code></pre></div>
<pre><code>## 
## Call:
## glm(formula = pa ~ WatrCont + Topo, family = binomial, data = mites)
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -2.0387  -0.5589  -0.1594   0.4112   2.0252  
## 
## Coefficients:
##              Estimate Std. Error z value Pr(&gt;|z|)    
## (Intercept)  4.464402   1.670622   2.672 0.007533 ** 
## WatrCont    -0.015813   0.004535  -3.487 0.000489 ***
## TopoHummock  2.090757   0.735348   2.843 0.004466 ** 
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 91.246  on 69  degrees of freedom
## Residual deviance: 48.762  on 67  degrees of freedom
## AIC: 54.762
## 
## Number of Fisher Scoring iterations: 6</code></pre>
</div>
<div id="interpreting-the-output-of-a-logistic-regression" class="section level2">
<h2><span class="header-section-number">8.2</span> Interpreting the output of a logistic regression</h2>
<p>The output of the previous logistic regression indicates that both water
content and topography are significant, but how do we interpret the
slope coefficients? Remember that we applied a transformation on our
expected values (<em>i.e.</em> the probability that Y = 1) so we have to use a
reverse function to properly interpret the results. We can use the
natural exponential function <code>ex</code> to obtain the odds of probability of
success for each explanatory variable.</p>
<div class="sourceCode" id="cb71"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb71-1"><a href="binomial-glms-bernouilli.html#cb71-1"></a>logit.reg</span></code></pre></div>
<pre><code>## 
## Call:  glm(formula = pa ~ WatrCont + Topo, family = binomial, data = mites)
## 
## Coefficients:
## (Intercept)     WatrCont  TopoHummock  
##     4.46440     -0.01581      2.09076  
## 
## Degrees of Freedom: 69 Total (i.e. Null);  67 Residual
## Null Deviance:       91.25 
## Residual Deviance: 48.76     AIC: 54.76</code></pre>
<p>How to obtain the odds of the slope? Use the “exp()” function to put
the coefficients back on the odds scale. Mathematically, this line of
code corresponds to:
<strong>exp(model coefficients) = exp(log(μ / (1 - μ)) = u / (1 - μ)</strong>.</p>
<p>This corresponds to an odds ratio!</p>
<div class="sourceCode" id="cb73"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb73-1"><a href="binomial-glms-bernouilli.html#cb73-1"></a><span class="kw">exp</span>(logit.reg<span class="op">$</span>coefficients[<span class="dv">2</span>])</span></code></pre></div>
<pre><code>##  WatrCont 
## 0.9843118</code></pre>
<p>To obtain confidence intervals on the odds scale:</p>
<div class="sourceCode" id="cb75"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb75-1"><a href="binomial-glms-bernouilli.html#cb75-1"></a><span class="kw">exp</span>(<span class="kw">confint</span>(logit.reg)[<span class="dv">2</span>,])</span></code></pre></div>
<pre><code>##     2.5 %    97.5 % 
## 0.9741887 0.9919435</code></pre>
<p>Note that the odds values here are considered when all other parameters
are kept constant. The topography parameter value is 8.09. It means that
the probability of observing <em>Galumna</em> sp. is 8.09 times more likely
when the topography is hummock compared to blanket.</p>
<p>When the odds value is smaller than 1, interpretation is a little bit
more complicated. When this is the case, we have to take the inverse
value (<em>i.e.</em> 1 divided by the odds) to facilitate interpretation. The
interpretation is then how <strong>LESS</strong> likely it is to observe the event of
interest. For water content, the odds is 0.984. The inverse is 1 / 0.984
= 1.0159. This means that a one-unit increase in water content decreases
the likelihood of observing <em>Galumna</em> sp. by 1.0159. We can also
substract 1 from the odds value to obtain a percentage: (1.0159 - 1) *
100 = 1.59% decrease in probability of observing <em>Galumna</em> sp. with a
one-unit increase in water content. To convince ourselves that it is an
appropriate interpretation, we can plot the presence of <em>Galumna</em> sp. as
a function of water content. We see that, on average, <em>Galumna</em> sp.
presence is higher at lower water content than its “absence”.</p>
<p><img src="images/galumna_pa.png" width="400" /></p>
<p>When the parameter estimate is between 0 and 1 on the odds scales, it
indicates a negative relationship between the response variable and the
explanatory variable. If the parameter is greater than 1, it indicates a
positive relationship between the response variable and the explanatory
variable. If the confidence interval includes 1, it indicates that the
variable is not significant. Remember that a value of 1 on the odds
scale means that the probability of Y = 1 is the same as the probability
of Y = 0 (<em>i.e.</em> when p = 0.5, 0.5/(1-0.5) = 1).</p>
<p>If you want to obtain the probabilities instead of the odds for each
explanatory variable, the inverse logit function is what you need:</p>
<p>logit<sup>-1</sup> = 1/(1+1/exp(x))</p>
<p>where x is the parameter to transform from log odds to the probability
scale. The parameter estimate of topography in our <code>logit.reg</code> model is
2.091, which is on the log odds scale. So, the probability value is
given by:</p>
<p>1/(1+1/exp(2.091)) = 0.89 which is the same as 1/(1+1/8.09). Remember
that the value 8.09 is on the odds scale. We have a 0.89 probability of
observing <em>Galumna</em> sp. when the topography is Hummock.</p>
<p>Let’s calculate this probability without using the exp() function:</p>
<p>First we start with our odds ratio for topography from the logit.reg model:
<strong>µ/ (1 - µ) = 8.09</strong></p>
<p>Let’s rearrange this to isolate µ
<strong>µ = 8.09(1 - µ) = 8.09 - 8.09µ</strong>
<strong>8.09µ + µ = 8.09</strong>
<strong>µ(8.09 + 1) = 8.09</strong>
<strong>µ = 8.09 / (8.09 + 1)</strong>
<strong>µ = 1 / (1 + (1 / 8.09)) = 0.89</strong></p>
<p>We obtained the same result!</p>
</div>
<div id="predictive-power-and-goodness-of-fit" class="section level2">
<h2><span class="header-section-number">8.3</span> Predictive power and goodness-of-fit</h2>
<p>An easy and intuitive way to evaluate the predictive power of your model
is to compare its deviance to the deviance of a null model. Deviance can
be understood as a generalisation of the residual sum of squares when
models are estimated by maximum likelihood (i.e. it is how parameters
are estimated in GLM). This allows us to compute a pseudo-R<sup>2</sup>
statistic, which is analogous to the coefficient of determination R<sup>2</sup>
in ordinary least square regression (i.e. the basic method for linear
models). The null model is a model without any explanatory variable. Its
notation in R is:
<code>null.model &lt;- glm(Response.variable ~ 1, family = binomial)</code>. The
generic formula to compute a pseudo-R<sup>2</sup> is given by:</p>
<p>Pseudo-R<sup>2</sup> = (null deviance – residual deviance) / null deviance</p>
<p>where “null deviance” is the deviance of the null model and “residual
deviance” is the deviance of the model of interest. The difference is
divided by the null deviance so that the result is bound between 0 and
1.</p>
<div class="sourceCode" id="cb77"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb77-1"><a href="binomial-glms-bernouilli.html#cb77-1"></a><span class="co"># Residual and null deviances are already stored in the glm object.</span></span>
<span id="cb77-2"><a href="binomial-glms-bernouilli.html#cb77-2"></a><span class="kw">objects</span>(logit.reg)</span></code></pre></div>
<pre><code>##  [1] &quot;aic&quot;               &quot;boundary&quot;          &quot;call&quot;             
##  [4] &quot;coefficients&quot;      &quot;contrasts&quot;         &quot;control&quot;          
##  [7] &quot;converged&quot;         &quot;data&quot;              &quot;deviance&quot;         
## [10] &quot;df.null&quot;           &quot;df.residual&quot;       &quot;effects&quot;          
## [13] &quot;family&quot;            &quot;fitted.values&quot;     &quot;formula&quot;          
## [16] &quot;iter&quot;              &quot;linear.predictors&quot; &quot;method&quot;           
## [19] &quot;model&quot;             &quot;null.deviance&quot;     &quot;offset&quot;           
## [22] &quot;prior.weights&quot;     &quot;qr&quot;                &quot;R&quot;                
## [25] &quot;rank&quot;              &quot;residuals&quot;         &quot;terms&quot;            
## [28] &quot;weights&quot;           &quot;xlevels&quot;           &quot;y&quot;</code></pre>
<div class="sourceCode" id="cb79"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb79-1"><a href="binomial-glms-bernouilli.html#cb79-1"></a>pseudoR2 &lt;-<span class="st"> </span>(logit.reg<span class="op">$</span>null.deviance <span class="op">-</span><span class="st"> </span>logit.reg<span class="op">$</span>deviance) <span class="op">/</span><span class="st"> </span>logit.reg<span class="op">$</span>null.deviance</span>
<span id="cb79-2"><a href="binomial-glms-bernouilli.html#cb79-2"></a>pseudoR2</span></code></pre></div>
<pre><code>## [1] 0.4655937</code></pre>
<p>Hence, the model explains 46.6% of the variability in the data.</p>
<p>An adjusted McFadden’s pseudo-R<sup>2</sup>, which penalizes for the number of
predictors, can be calculated as below:</p>
<p><span class="math display">\[ R^2_{adj} = \frac{null~deviance - residual~deviance}{null~deviance} \]</span>
<span class="math display">\[ R^2_{adj} = 1 - \frac{logL(M)-K}{logL(M_{null})} \]</span></p>
<p>where <strong>K</strong> corresponds to the additional number of predictors in
relation to the null model.</p>
<p>The goodness-of-fit of logistic regression models can be expressed by
variants of <span class="math inline">\(pseudo-R^2\)</span> statistics, such as Maddala (1983) or Cragg and
Uhler (1970) measures.</p>
<p>When talking about logistic regressions, low R<sup>2</sup> values are common.</p>
<p>The R function <code>DescTools::PseudoR2()</code> makes it possible to calculate
many types of <span class="math inline">\(pseudo-R^2\)</span>. By specifying <code>which = all</code>, calculate all
of them at once.</p>
<div class="sourceCode" id="cb81"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb81-1"><a href="binomial-glms-bernouilli.html#cb81-1"></a>logit.reg &lt;-<span class="st"> </span><span class="kw">glm</span>(pa <span class="op">~</span><span class="st"> </span>WatrCont <span class="op">+</span><span class="st"> </span>Topo,</span>
<span id="cb81-2"><a href="binomial-glms-bernouilli.html#cb81-2"></a>                 <span class="dt">data =</span> mites, <span class="dt">family =</span> <span class="kw">binomial</span>(<span class="dt">link =</span> <span class="st">&quot;logit&quot;</span>))</span>
<span id="cb81-3"><a href="binomial-glms-bernouilli.html#cb81-3"></a>DescTools<span class="op">::</span><span class="kw">PseudoR2</span>(logit.reg, <span class="dt">which =</span> <span class="st">&quot;all&quot;</span>)</span></code></pre></div>
<pre><code>##        McFadden     McFaddenAdj        CoxSnell      Nagelkerke   AldrichNelson 
##       0.4655937       0.3998373       0.4549662       0.6245898       0.3776866 
## VeallZimmermann           Efron McKelveyZavoina            Tjur             AIC 
##       0.6674318       0.5024101       0.7064093       0.5114661      54.7623962 
##             BIC          logLik         logLik0              G2 
##      61.5078819     -24.3811981     -45.6229593      42.4835224</code></pre>
<div id="challenge-2" class="section level3">
<h3><span class="header-section-number">8.3.1</span> Challenge 2</h3>
<p>Assess goodness-of-fit and predictive power of the <code>model.bact2</code> model. How can you improve the predictive power of this model?</p>
</div>
<div id="challenge-2-solution" class="section level3">
<h3><span class="header-section-number">8.3.2</span> Challenge 2: Solution</h3>
<div class="sourceCode" id="cb83"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb83-1"><a href="binomial-glms-bernouilli.html#cb83-1"></a>null.d &lt;-<span class="st"> </span>model.bact2<span class="op">$</span>null.deviance</span>
<span id="cb83-2"><a href="binomial-glms-bernouilli.html#cb83-2"></a>resid.d &lt;-<span class="st"> </span>model.bact2<span class="op">$</span>deviance</span>
<span id="cb83-3"><a href="binomial-glms-bernouilli.html#cb83-3"></a>bact.pseudoR2 &lt;-<span class="st"> </span>(null.d <span class="op">-</span><span class="st"> </span>resid.d) <span class="op">/</span><span class="st"> </span>null.d</span>
<span id="cb83-4"><a href="binomial-glms-bernouilli.html#cb83-4"></a>bact.pseudoR2</span></code></pre></div>
<pre><code>## [1] 0.0624257</code></pre>
<p>This is very low!</p>
<p>Adding informative explanatory variables could increase the explanatory power of the model.</p>
<p>But, do not be afraid of non-significant results!</p>
</div>
</div>
<div id="plotting-results" class="section level2">
<h2><span class="header-section-number">8.4</span> Plotting results</h2>
<p>Once we’ve created a model and verified its validity, we can plot the
results to show how the response variable is related to some explanatory
variables. One way to graphically summarise the data is by plotting both
the response variable and the expected values as a function of some
predictor. Here is an example with the <code>ggplot2</code> package. See <a href="r_workshop3">workshop
3</a> for more information on this package.</p>
<div class="sourceCode" id="cb85"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb85-1"><a href="binomial-glms-bernouilli.html#cb85-1"></a><span class="kw">ggplot</span>(mites,</span>
<span id="cb85-2"><a href="binomial-glms-bernouilli.html#cb85-2"></a>  <span class="kw">aes</span>(<span class="dt">x =</span> WatrCont, <span class="dt">y =</span> pa)) <span class="op">+</span></span>
<span id="cb85-3"><a href="binomial-glms-bernouilli.html#cb85-3"></a><span class="st">  </span><span class="kw">geom_point</span>() <span class="op">+</span></span>
<span id="cb85-4"><a href="binomial-glms-bernouilli.html#cb85-4"></a><span class="st">  </span><span class="kw">stat_smooth</span>(<span class="dt">method =</span> <span class="st">&quot;glm&quot;</span>, <span class="dt">family=</span> <span class="st">&quot;binomial&quot;</span>, <span class="dt">se =</span> <span class="ot">FALSE</span>) <span class="op">+</span></span>
<span id="cb85-5"><a href="binomial-glms-bernouilli.html#cb85-5"></a><span class="st">  </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">&quot;Water content&quot;</span>,</span>
<span id="cb85-6"><a href="binomial-glms-bernouilli.html#cb85-6"></a>  <span class="dt">y =</span> <span class="st">&quot;Probability of presence&quot;</span>,</span>
<span id="cb85-7"><a href="binomial-glms-bernouilli.html#cb85-7"></a>  <span class="dt">title =</span> <span class="st">&quot;Probability of presence of Galumna sp. as a function of water content&quot;</span>) <span class="op">+</span></span>
<span id="cb85-8"><a href="binomial-glms-bernouilli.html#cb85-8"></a><span class="st">  </span><span class="kw">theme_classic</span>() <span class="co"># applies a simplified plot theme</span></span></code></pre></div>
<p><img src="book-en_files/figure-html/unnamed-chunk-60-1.png" width="672" style="display: block; margin: auto;" /></p>

</div>
</div>



<hr>
<center> 
  <div class="footer">
      All the content of the workshop series is under a <a href="https://creativecommons.org/licenses/by-nc/2.0/">Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License</a>.
  </div>
</center>
            </section>

          </div>
        </div>
      </div>
<a href="binary-variables.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="binomial-glms.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": false
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "section"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
