---
output:
  pdf_document: default
  html_document: default
---
# Révision des modèles linéaires

La plupart de nos recherches tentent d'expliquer des tendances dans nos observations à l'aide de variables prédictives. 

Nous cherchons souvent une fonction $f$ qui explique une variable réponse ( $Y$ ) *en fonction* d'une ( $X_1$ ) ou de plusieurs variables prédictives ( $X_2$, $X_3$, $...$, $X_n$ ):

$$Y = f(X_1)$$
L'ensemble de variables prédictives que nous avons mesuré ne pourra jamais complètement expliquer notre variable $Y$. Il y a une **variation imprévisible** dans nos modèles, i.e. l'erreur $\epsilon$, qui fera toujours partie de notre fonction:

$$Y = f(X_1, \epsilon)$$
Dans l'[atelier 4](https://qcbsrworkshops.github.io/workshop04/pres-fr/workshop04-pres-fr.html#1), nous avons appris comment utiliser les modèles linéaires généraux pour décrire la relation entre variables. Ces modèles comportent les test de $t$, les analyses de variances (ANOVA), les régressions linéaires (simple ou avec plusieurs variables prédictrices) et les analyses de covariance (ANCOVA).

## Modèles linéaires généraux

### Definition

La formule générale de notre fonction linéaire $Y = f(X_1)$ serait représentée comme: 

$$Y = \beta_0 + \beta_1X_i + \varepsilon$$

où:

$Y_i$ est la valeur prédite de la variable réponse

$\beta_0$ est le *coefficient inconnu* de l'**ordonnée à l'origine**

$\beta_1$ est le *coefficient inconnu* de la **pente**

$X_i$ est la valeur de la variable explicative

$\varepsilon_i$ représente les résidus du modèle obtenus d'une distribution normale de moyenne 0 et de variance constante (qui est à estimer).

### Conditions d'utilisation

Nous avons aussi appris que les **modèles linéaires** produisent seulement des estimateurs non-biaisés (c'est-à-dire, sont seulement fiables) si ils suivent quelques conditions. Notamment:

1\. La population peut être décrite par une relation linéaire:

$$Y = \beta_0 + \beta_1X_i + \varepsilon$$

2\. Le terme d'erreur $\varepsilon$ a la même variance quelque soit la valeur de la variable explicative (c'est-à-dire, l'homoscédasticité), et les termes d'erreur ne sont pas corrélés entre les observations (donc, il n'y a pas d'autocorrélation).

$$\mathbb{V}{\rm ar} (\epsilon_i | \mathbf{X} ) = \sigma^2_\epsilon,\ \forall i = 1,..,N$$
et,

$$\mathbb{C}{\rm ov} (\epsilon_i, \epsilon_j) = 0,\ i \neq j$$

3\. Les résidus suivent une distribution normale:

$$\boldsymbol{\varepsilon} | \mathbf{X} \sim \mathcal{N} \left( \mathbf{0}, \sigma^2_\epsilon \mathbf{I} \right)$$

Les estimations d'un modèle général linéaire telles que $\widehat{Y} = \widehat{\beta}_0 + \widehat{\beta}_1 X$ assumemt que les données sont générées selon les conditions présentées. 

```{r echo = FALSE, fig.width = 8, fig.height = 8}
# Set the coefficients:
N = 50
beta_0 = 1
beta_1 = 0.5

# Generate sample data:
x <- 0:N
e <- rnorm(mean = 0, sd = 1.5, n = length(x))
y <- beta_0 + beta_1 * x + e

# Plot the data
plot(x, y)

# The regression equation:
y_dgp <- beta_0 + beta_1 * x

# Plot regression:
lines(x = x, y = y_dgp, col = "darkgreen", lty = 2)

legend(x = 0, y = 25,
       legend = c(expression(paste("Y = ", beta[0] + beta[1] * X))),
       lty = c(2, 1), lwd = c(1, 1), pch = c(NA, NA), col = c("darkgreen", "blue"))
```


## Un exemple avec les modèles linéaires généraux

Simulons 250 unités d'observation qui satisfaient nos conditions d'application:  $\epsilon_i \sim \mathcal{N}(0, 2^2), i = 1,...,250$.

```{r}
nSamples <- 250
ID <- factor(c(seq(1:nSamples)))

PredVar <- runif(nSamples,min = 0,max = 50)

simNormData <- data.frame(ID = ID,PredVar = PredVar,RespVar = (2*PredVar + rnorm(nSamples,mean = 0,sd = 2)))

lm.simNormData <- lm(RespVar ~ PredVar, 
                     data = simNormData)
```

```{r}
layout(matrix(c(1,2,3,4),2,2)) 
plot(lm.simNormData)
```

1. Ces graphiques permettent de vérifier les conditions d'application de la linéarité et l'homoscédasticité.

2. Le graphique QQ permet la comparaison des résidus avec une distribution normal. 

3. Scale-location plot (la racine carré des résidus standardisés vs. valeur prédite) est utile pour vérifier l'homoscédasticité;

4. La distance de Cook est une mesure d'influence des observations sur le coefficient de la régression linéaire et permet d'identifier des données aberrantes.

Les résidus équivaut $Y-\widehat{Y}$, soit la valeur observée par la valeur prédite par le modèle. 

Les données aberrantes sont des observations avec des résidus larges, i.e. la valeur observée ($Y$) pour un point ($x$) est très différente de la valeur prédite par le modèle linéaire ($\widehat{Y}$).

Un point de levier est défini comme une observation $Y$ qui a une valeur de $x$ qui est très éloignée de la moyenne de $x$. 

Une observation influente est défini par une observation $Y$ qui change la pente de la relation $\beta_1$. Donc, un point influent va avoir une influence élevée sur la prédiction du modèle. Une méthode pour trouver des observations influentes est de comparer un modèle avec et sans la dite observation. 

## Un exemple avec des vrais données des modèles linéaires généraux

Utilisons nos connaissances des modèles linéaires généraux pour explorer la relation entre les variables dans le *jeu de données de mites Orbatid*.

Commençons par charger les données dans `R`:

```{r echo=TRUE}
# Use setwd() to set your working directory

mites <- read.csv('data/mites.csv',
                  stringsAsFactors = TRUE)
```

Le jeu de données que vous avez chargé est un échantillon du jeu de données [mites Oribatid (Acari,Oribatei)](http://adn.biol.umontreal.ca/~numericalecology/data/oribates.html), qui a été utilsé pour plusieurs textes (e.g. Borcard,
Gillet & Legendre, *Numerical Ecology with R*), et est disponible avec le package `vegan`.

Le jeu de données `mites` contient **70 échantillons de mousses et mites** récoltés par la [Station de Biologie de l'Université de Montréal](https://goo.gl/maps/PxN1Q7KUPnUt92Eu5).
] provenant de la municipalité de Saint-Hippolyte, Québec (Canada). Il contient **5 variables environmentales**, l'abondance de la mite *Galumna* sp., et l'abondance totale des mites. 

Nous pouvons examiner la structure du jeu de données avec les fonctions `head()` and `str()` functions:

```{r, echo = TRUE, eval = TRUE}
head(mites)

str(mites)
```

Notre première vue su jeu de données nous permet déjà de séparer les variables potentielles en variables réponses ou variables prédictrices:

<div class = "split">
<div class = "split-left">

Variables réponses:

1. Occurrence: `pa`
2. Abondance: `Galumna`
3. Fréquence relative ou Proportions: `prop`
</div>

<div class = "split-right">

Variables prédictrices:

1. Densité du substrat: `SubsDens`
2. Contenu en eau (du sol): `WatrCont`
3. Substrat: `Substrate`
4. Arbustes: `Shrub`
5. Topographie: `Topo`

</div>
</div>

Quelles questions pouvons-nous poser avec ces variables?
<br>
**Est-ce que l'environnement permet de prédire l'abondance, l'occurrence, ou la proportion de *Galumna* sp.?**

Pour répondre à ces questions nous pouvons élaborer plusieurs fonctions:

<div class = "split">
<div class = "split-left">

$\text{Abondance} = f(\text{Contenu en eau}, \epsilon)$

$\text{Proportion} = f(\text{Contenu en eau}, \epsilon)$

$\text{Occurrence} = f(\text{Substrat}, \epsilon)$

$\text{Abondance} = f(\text{Topographie}, \epsilon)$

</div>

<div class = "split-right">

$\text{Occurrence} = f(\text{Arbustes}, \epsilon)$

$\text{Fréquence relative} = f(\text{Topographie}, \epsilon)$

$\text{Occurrence} = f(\text{Densité du substrat}, \epsilon)$

$\text{Abondance} = f(\text{Substrat}, \epsilon)$
]

</div>
</div>

Pouvons-nous voir une relation entre *Galumna* et une ou plusieurs des cinq variables environnementales?

Essayons en cherchant si **la communauté de *Galumna* (abondance, occurrence and fréquence relative) varie en fonction du contenu en eau**.

Nous pouvons commencer en représentant les trois varaibles réponses avec la variable prédictrice:

```{r, echo = TRUE, eval = TRUE}
plot(Galumna ~ WatrCont,
     data = mites,
     xlab = 'Water content',
     ylab = 'Abundance')
```

```{r, echo = TRUE, eval = TRUE}
boxplot(WatrCont ~ pa,
        data = mites,
        xlab='Presence/Absence',
        ylab = 'Water content')
```

```{r, echo = TRUE, eval = TRUE}
plot(prop ~ WatrCont,
     data = mites,
     xlab = 'Water content',
     ylab = 'Proportion')
```

En effet, `Galumna` semble varier négativement avec la fonction de `WatrCont`, *i*.*e*. *Galumna* sp. préfèrerait des sites plus secs.

Nous pouvons aller plus loin encore en testant un modèle linéaire avec `Galumna`, `pa`, ou `prop` en fonction de `WatrCont`

```{r, eval = -c(2, 5, 8)}
# Fit the models

# Abundance model
lm.abund <- lm(Galumna ~ WatrCont, data = mites)

# Presence-absence model
lm.pa <- lm(pa ~ WatrCont, data = mites)

# Proportion model
lm.prop <- lm(prop ~ WatrCont, data = mites)
```

Nous pouvons vérifier si la relation est significative avec sa sortie du modèle:

```{r, echo = TRUE, eval = TRUE}
# Check the model output with the summary() function
summary(lm.abund)
```

```{r, echo = TRUE, eval = TRUE}
summary(lm.pa)
```

```{r, echo = TRUE, eval = TRUE}
summary(lm.prop)
```

```{r}
# Extracting the Pr(>|t|)

summary(lm.abund)$coefficients[, 4]
summary(lm.pa)$coefficients[, 4]
summary(lm.prop)$coefficients[, 4]
```
En effet, il y a une forte relation significative avec les 3 variables réponses! **Mais attendez...** Nous avons oublier de faire la chose la plus important! Soit de vérifier les conditions d'application du modèle linéaire!

## Les conditions d'application d'un modèle linéaire

Validons nos modèles pour s'assurer qu'ils suivent les conditions d'application des modèles linéaires, en commençant avec le modèle d'abondance.


```{r, echo = TRUE, eval = TRUE, fig.width = 7, fig.height = 7, fig.align = "center"}
# Plot the abundance model
plot(Galumna ~ WatrCont, data = mites)
abline(lm.abund)
```

Le modèle ne suit pas bien les données observées. Il prédit une abondance négative lorsque `WatrCont` dépasse `600`, ce qui n'est pas réaliste pour notre jeu de données qui ne peut pas avoir de données négatives. Le modèle performe aussi très mal quand il en vient à prédire les valeurs d'abondance à hautes valeurs de `WatrCont`.

Examinons les graphiques de diagnostique:

```{r, echo = TRUE, eval = TRUE, fig.show="hold", out.width = "50%", out.height = "50%"}
# Diagnostic plots
plot(lm.abund)
```

Les graphiques montre que le modèle viole les conditions d'homogénéité de la variance. En effet, le graphique en haut à gauche montre que les résidus sont plus larges lorsque les valeurs prédites sont élevés. Le modèle ne suit pas non plus la conditons de normalité; le graphique en haut à droite indique que les résidus ne suivre pas une courbe normale aux extrémités et beaucoup de points sont très éloignés de la valeur prédite (ligne pointillée).

Nous devons rejeter ce modèle et ne pouvons conclure quoi que ce soit sur l'abondace de *Galumma* selon le contenu en eau.

Nous pouvons regarder les graphiques de diagnostique du modèle de fréquence relative et de présence-absence, mais nous observons des problèmes similaires:

```{r, echo = TRUE, eval = TRUE, fig.width = 7, fig.height = 7, fig.align="center"}
# Plot the proportion model
plot(prop ~ WatrCont, data = mites)
abline(lm.prop)
```

```{r, echo = TRUE, eval = TRUE, fig.show = "hold", out.width="50%", out.height="50%"}
# Diagnostic plots
plot(lm.prop)
```

```{r, echo = TRUE, eval = TRUE, fig.width = 7, fig.height = 7, fig.align="center"}
# Plot the presence/absence model
plot(pa ~ WatrCont, data = mites)
abline(lm.pa)
```

```{r, echo = TRUE, eval = TRUE, fig.show = "hold", out.width="50%", out.height="50%"}
# Diagnostic plots
plot(lm.pa)
```

Reculons un peu et révisons les conditions d'application des modèles linéairesLet's take a step back here and review the assumptions of linear models, and where they come from. Remember our simple linear model?

$$Y_i = \beta_0 + \beta_1X_i + \varepsilon$$

La dernière variable $\varepsilon_i$ est très importante. C'est de là que les conditions d'application du modèle prennent origine. Pour les modèles linéaires, **les résidus $\varepsilon_i$ (la distance entre une observation et la droite de régression) peuvent être prédits en dessinant une variable aléatoire provenant d'une distribution normale.**

Rappelez-vous que les distributions normales ont deux paramètres: $\mu$ (la moyenne de la distribution) et $\sigma^2$ (la variance de la sitribution). Pour un modèle linéaire, $\mu$ change selon la valeur de $X$ (variable prédictrice), mais $\sigma^2$ a la même valeurs pour toutes les valeurs de $Y$. Notre modèle linéaire simple peut aussi être écrit de cette façon:

$$Y_i \sim N(\mu = \beta_0 + \beta_1 X_i +\varepsilon, \sigma^2)$$

où $N(\cdot)$ indique que $Y_i$ provient d'une **distribution normale** avec le paramètre $\mu$ (moyenne; qui dépend de $x_i$) et $\sigma$ (variance; qui a la même valeur pour toutes les valeurs de $Y_i$).

Qu'arrive-t-il si on fait varier les valeurs de $\mu$ et $\sigma$.

En faisant varier $\mu$ alors $\sigma = 5$ fait changer la moyenen de la distribution.

```{r, echo = FALSE, fig.align="center", fig.width = 7, fig.height = 7}
# Demonstrating normal distributions with different means
x = seq(1, 50, 0.1)
plot(x, dnorm(x, mean = 20, sd = 5),
type = 'l', lwd = 3,
xlab = '# galumna', ylab = 'Probability')
points(x, dnorm(x, mean = 25, sd = 5),
type = 'l', lwd = 3, col = 2)
points(x, dnorm(x, mean = 30, sd = 5), type = 'l', lwd = 3, col = 4)
legend('topleft', legend = c('20', '25', '30'), lty = 1, col = c(1,2,4), bty = 'n', lwd = 2, cex = 1.1)
```

Si nous gardons $\mu = 25$, en faisant varier $\sigma$ , la forme e la distribution change, où un petit $\sigma$ (variance basse) indique que la probabilité est plus élevé autour de la moyenne, alors qu'un $\sigma$ élevé diffuse la probabilité à traver l'étendue des données.

```{r, echo=FALSE, fig.align="center", fig.width = 7, fig.height = 7}
# Demonstrating normal distributions with different variance
x = seq(1, 50, 0.1)
plot(x, dnorm(x, mean = 25, sd = 5), type = 'l', lwd = 3, xlab = '# galumna', ylab = 'Probability')
points(x, dnorm(x, mean = 25, sd = 7.5), type = 'l', lwd = 3, col = 2)
points(x, dnorm(x, mean = 25, sd = 10), type = 'l', lwd = 3, col = 4)
legend('topleft', legend = c('5', '7.5', '10'), lty = 1, col = c(1,2,4), bty = 'n', lwd = 2, cex = 1.1)
```

### Prédiction du modèle

Lorsque les conditions d'application du modèle linéairene sont pas rencontrées, les prédiction du modèle deviennent problématiques. Regardons un exemple pour démontrer les problèmes associés avec un modèle mal estimé.

Rappel: nous voulons estimer les *coefficients inconnus* $\beta_0$ et $\beta_1$, pour tracer une ligne droite qui prédit chaque valeur de $Y$ en fonction de $X$!

$$Y_i \sim N(\mu = \beta_0 + \beta_1 X_i +\varepsilon, \sigma^2)$$

Prédisons l'abondance de *Galumna* pour un contenu en eau = 300 avec notre modèle linéaire général. **Quels sont les paramètres de la distribution normale utilisée pour modéliser $Y$ quand le contenu en eau est $300$?**

Nous commençons par obtenir les valeurs de $\mu$ and $\sigma^2$ pour une distribution correspondant à notre modèle. Pour obtenir les coefficient de nos modèles, on peut utiliser la fonction `coef()`:

```{r, echo = TRUE}
# Extract model coefficients
coef(lm.abund)
```

Ces coéfficients nous permettrais de prédire l'abondance de *Galumna* s'il n'y avait pas d'erreur. Cepenant, nous savons que l'erreur est **irrévocable** pour notre modèle. Pour avoir nos valeurs prédites, nous avons donc besoin d'ajouter \varepsilon. C'Est ici que nous utilisons la distribution normale! Pour $X$ = 300, notre modèle prédit que \varepsilon devrait suivre une distribution normale avec une moyenne = 1.63. Nous pouvons extraire la variance ($\sigma^2$) avec le sommaire du modèle:

```{r, echo = TRUE}
# Extract variance from the model summary
summary(lm.abund)$sigma
```

Nous pouvons intégrer ces valeurs avec l'équation du modèle:
$$Y_i \sim N(\mu = \beta_0 + \beta_1 X_i +\varepsilon, \sigma^2)$$
$\mu = 3.44 + (-0.006 \times 300) = 1.63$

$\sigma^2 = 1.51$

Ceci nous indique que des valeurs de $Y$ générées aléatoirement lorsque le contenu en eau = $300$ devrait être $1.63$ en moeynne et avoir un variance de $1.51$. À $x = 300$, résidus devrait suivre une distribution normale avec $\mu = 1.63$ et $\sigma^2 = 1.51$. À $x = 400$, nous avons $\mu = 1.02$ et $\sigma^2 = 1.51$, etc.


Lorsque le contenu en eau = 400, résidus \varepsilon devrait suivre une distribution ormale dont les paramètres $\mu = 3.44 + (-0.006 x 400) = 1.02$ et $\sigma^2 = 1.51$, etc. Chaque valeur de $Y$ est modélisé selon une distribution normale avec une moyenne qui dépend de $X_i$, mais avec la variance qui est constante $\sigma^2 = 1.51$ pour toutes les valeurs de $X_i$. Sur un graphique, cela ressemblerait à:

![](images/modelPredic.png){width="400"}

Les quatre distributions normales (en orange) sur ce graphique représentent la probabilité d'observer une valeur d'abondance de *Galumna* donnée pour quatre valeurs différentes de contenu en eau. La moyenne de la distribution normale varie selon une fonction du contenu en eau (donc $\mu$  diminue avec le contenu en eau), mais $\sigma^2$ est toujorus = 1.51 (i.e. la variance est homogène pour toutes les valeurs de $X$).

Ce modèle est innaproprié pour au moins deux raisons:

**1.  Les valeurs sont en moyenne, plus éloignée de la pente à une valeur de X basse qu'à une valeur de X élevée, ce qui indique que la variance (σ2) n'est pas homogène.** Il y a plus de variance résiduelle autour des valeurs prédites à une valeurs basse de $X$, d'une façon que $\varepsilon$ varie en fonction de $X$, et ainsi violant la condition de l'homoscédasticité. Ce n'est pas réaliste d'utiliser une valeur de $\sigma^2$ constante: la distribution normale utilisée pour prédire $Y$ à de faibles valeurs de $X$ devrait idéalement être plus large (une variance $\sigma^2$ plus large) que la distribution normale utilisée pour prédire $Y$ pour de grandes valeurs de $X$, mais le modèle linéaire ne permet pas cela.

**2. Les résidus ne suivent pas une distribution normale avec une variance constante pour toutes les valeurs de** $X$. La distribution de la variance des résidus changent selon une fonction de $X$ (observer l'étendue des données aoutut de la ligne de tendance!).

**3. Les valeurs prédites ne font pas de sens, selon les observations données.** Notre variable réponse est l'abondance, qui est une variable dicrète. Pourtant, pour un contenu en eau = 300, la valeur d'abondance que notre modèle prédit comme étant la plus probable d'observer est 1.63! Nous savons que la probabilité d'observer 1.63 individuals pour une contenu en eau = 300 est actuellement de 0, puisque la probabilité d'observer n'importe quelle fraction (non-discrète) est impossible. Nos valeurs prédites devraient être modélisées en utilisant une distribution qui prédit seulement avec des variables discrètes, plutôt que continus. Ceci est un problème commun, puisque les données biologiques suivent souvent une myriades d'autres distributions statistiques autre que la distribution normale. 

### Que faire? Transformer nos données?

Très souvent, nos données ne vont pas se comporter adéquatement et vont violer les conditions d'applications, ce qui indique la **non-normalité** et **hétéroscédasticité**.

Certains vous dirons de **transformer** vos données avec un logarithme, la racine carré ou un cosine remédier à ce problème . Malheureusement, les transformations ne marhcent pas toujours et viennent souvent avec des inconvénients:

**1.**  Cela change la variable réponse (!), rendant l'interprétation difficile;
**2.**  Les transformations ne vont pas toujours améliorer la linéarité et l'homogénéité de la variance;
**3.**  Les limites spatiales de l'échantillon changent. 

Par exemple, notre modèle linéaire simple:

$$Y_i = \beta_0 + \beta_1X_i + \varepsilon$$

ressemble à ceci lorsqu'on le transforme avec un logarithme:

$$E(\log{Y_i}) = \beta_0 + \beta_1X_i $$

C'est, de toute évidence, moins intuitif à interpréter pour chaque augmentation de $300$ unités en contenu en eau, l'abondanc de *Galumna* prend la forme de $\log(1.63)$...

Heureusement, la **distribution normale n'est pas notre seule option!**
