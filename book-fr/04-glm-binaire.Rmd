# (PART\*) GLM avec des données binaires {-}

# GLM avec une distribution binomiale (Bernouilli)

Les variables binaires sont fréquentes en écologie : on observe un
phénomène X ou son \«absence\». Par exemple, on note souvent la présence
ou l'absence d'espèces lors d'études de terrain. Le but est
généralement de déterminer si la présence d'une espèce est influencée
par différentes variables environnementales. D'autres exemples courants
sont la présence/absence d'une maladie au sein d'une population
sauvage, l'observation/non-observation d'un comportement spécifique et
la survie/mort d'un individu. Un modèle de régression qui utilise une
variable binaire comme variable réponse est l'un de plusieurs modèles
linéaires généralisés (GLM) et est appelé régression logistique ou
modèle logit.

Dans R, la présence (ou succès, survie...) est habituellement codée par
un `1` et une absence (ou échec, mort...) par un `0`. On effectue une
régression logistique (ou n'importe quel GLM) à l'aide de la fonction
`glm()`. Cette fonction diffère un peu de la fonction de base `lm()`,
car elle permet de spécifier une distribution statistique autre que la
distribution normale. Nous avons déjà vu que les variables binaires ne
sont pas distribuées normalement (*i.e.* on observe un pic à 0 et un pic
à 1 et rien entre les deux). La dernière section a montré que la
distribution de Bernoulli est appropriée pour modéliser les variables
réponses binaires. La moyenne de cette distribution est représentée par
la probabilité *p* d'observer un résultat et la variance est calculée
par *p*\*(1 - *p*). Le terme (1 - *p*) représente la probabilité de ne
**pas** observer un résultat. Dans R, on spécifie la distribution
statistique du modèle avec l'argument `family`. Pour la régression
logistique, on l'indique de la façon suivante : `family = 'binomial`'.
Rappelez-vous que la distribution de Bernoulli est un cas spécifique de
la distribution binomiale lorsque le nombre de répétitions est égal à 1:
R \«comprend\» qu'il faut utiliser une distribution de Bernoulli.

Lorsqu'on prédit la probabilité d'observer un phénomène Y qui est une
variable binaire, la valeur prédite doit se trouver entre 0 et 1 :
c'est l'étendue possible d'une probabilité ! Si on utilise un modèle
linéaire de base pour modéliser une variable binaire en fonction de
variables explicatives, il est fort possible qu'on obtienne des valeurs
prédites qui se retrouvent en dehors de l'intervalle [0,1], ce qui ne
fait aucun sens. L'exemple suivant va vous permettre de mieux
comprendre pourquoi un modèle linéaire traditionnel est inapproprié. La
prochaine sous-section va vous montrer comment éviter ce problème avec
une fonction de lien. Brièvement, une fonction de lien est utilisée pour
linéariser la relation entre les valeurs prédites d'un modèle et le
prédicteur linéaire (voir sous-section suivante).

```{r, echo = FALSE, eval = TRUE}
mites <- read.csv('mites.csv')
```
```{r, echo = TRUE, eval = TRUE}
model.lm <- lm(pa ~ WatrCont + Topo, data = mites)
fitted(model.lm)
# La fonction «fitted()» extrait les valeurs prédites de la variable réponse du modèle linéaire.
# Certaines valeurs sont en-dessous de 0, ce qui ne fait pas de sens pour une régression logistique.
# Essayons le même modèle, mais avec une distribution binomiale cette fois-ci.
# Remarquez l'argument «family» pour spécifier la distribution.
model.glm <- glm(pa ~ WatrCont + Topo, data = mites, family = binomial)
fitted(model.glm)
# Toutes les valeurs sont comprises entre 0 et 1.
```

## La fonction de lien

Afin d'éviter les biais reliés aux modèles linéaires de base, nous
avons besoin de spécifier deux choses : une distribution statistique
pour les résidus du modèle et une fonction de lien pour les valeurs
prédites par ce même modèle. Nous avons déjà vu la distribution de
Bernoulli dans la section précédente, alors nous passerons directement à
l'explication du rôle de la fonction de lien.

Pour un modèle de régression linéaire d'une variable réponse continue
distribuée normalement, l'équation suivante nous permet d'obtenir les
valeurs prédites de la variable réponse :

*μ* = *Xβ*

où *μ* est la valeur prédite de la réponse variable, *X* est la matrice
du modèle (*i.e.* ça représente les variables explicatives) et *β*
correspond aux paramètres estimés à partir des données (*i.e.*
l'intercept et la pente). Le terme *Xβ* est appelé le prédicteur
linéaire. En termes mathématiques, c'est le produit matriciel de la
matrice du modèle *X* et du vecteur des paramètres estimés *β*.
Regardons cela de plus près dans R :

```{r, echo = FALSE, eval = TRUE}
#Petite fonction ajoutée pour que seules les lignes désirées sortent dans le prochain bloc!
#Source: https://bookdown.org/yihui/rmarkdown-cookbook/hook-truncate.html
# save the built-in output hook
hook_output <- knitr::knit_hooks$get("output")

# set a new output hook to truncate text output
knitr::knit_hooks$set(output = function(x, options) {
  if (!is.null(n <- options$out.lines)) {
    x <- xfun::split_lines(x)
    if (length(x) > n) {
      # truncate the output
      x <- c(head(x, n), "....\n")
    }
    x <- paste(x, collapse = "\n")
  }
  hook_output(x, options)
})
```
```{r, echo = TRUE, eval = TRUE, out.lines = 10}
# Chargez le jeu de données CO2 utilisé dans un atelier précédent
data(CO2)
head(CO2)
# Construisez un modèle linéaire de l'absorption de CO2 en fonction de la concentration ambiante de CO2.
model.CO2 <- lm(uptake ~ conc, data = CO2)
# On extraie la matrice du modèle avec la fonction model.matrix().
X <- model.matrix(model.CO2)
# Les paramètres estimés sont extraits ainsi :
B <- model.CO2$coefficients
# On multiple X et B pour obtenir le prédicteur linéaire.
# Le symbole «%*%» indique qu'on veut effectuer le produit matriciel.
XB <- X %*% B
# On compare les valeurs de XB aux valeurs obtenues avec la fonction fitted().
# Toutes les déclarations devraient être vraies (i.e. TRUE).
# On utilise la fonction round() pour que tous les éléments aient cinq décimales.
round(fitted(model.CO2), digits = 5) == round(XB, digits = 5)
```

Lorsqu'on crée un modèle linéaire simple avec une variable réponse
continue distribuée normalement, le prédicteur linéaire est égal aux
valeurs attendues de la variable réponse. Ceci n'est pas exact si la
variable réponse n'est pas distribuée normalement. Si c'est le cas, il
faut appliquer une transformation sur les valeurs prédites, *i.e.* une
fonction de lien. La fonction de lien peut être vue comme une
transformation des valeurs prédites pour obtenir une **relation
linéaire** entre celles-ci et le prédicteur linéaire :

*g*(*μ*) = *Xβ*

où *g*(*μ*) est la fonction de lien des valeurs prédites. Ceci permet
d'enlever la contrainte de distribution normale des résidus. Lorsque la
variable réponse est une variable binaire, la fonction de lien est la
fonction logit et est représentée par l'équation suivante :

logit(*μ*) = log (*μ* / 1-*μ*) = *Xβ*

où *μ* représente les valeurs prédites (*i.e.* la probabilité que Y = 1,
car on observe la présence d'une espèce, d'une maladie, d'un succès
ou d'un autre événement). Le ratio *μ* / 1-*μ* représente la cote (odds
en anglais) qu'un événement se produise. Cela transforme les valeurs
prédite sur une échelle de 0 à l'infini. Par exemple, si on a une
probabilité de 0,8 d'observer une espèce X, la cote est donc de 4 : il
est 4 fois plus probable d'observer l'espèce que de ne pas l'observer
- 0.8/(1-0.8) = 4. La transformation log (on appelle maintenant ce ratio
le log odds) permet aux valeurs d'être distribuées de moins l'infini à
l'infini. Donc, la fonction de lien logit prend les valeurs prédites du
modèle et les transforme en une variable continue sans borne. Les
valeurs prédites peuvent ainsi être reliées à un prédicteur linéaire.
C'est pour cette raison qu'on appelle ce modèle un modèle **linéaire**
généralisé même si la relation entre la variable réponse et la variable
explicative ne ressemble pas nécessairement à une \«ligne droite\» !

```{r, echo = TRUE, eval = TRUE}
# On construit un modèle de régression de la présence/absence d'une espèce de mite (Galumna sp.)
# en fonction du contenu en eau du sol et de la topographie.
# On utilise la fonction glm() et on spécifie l'argument «family».
logit.reg <- glm(pa ~ WatrCont + Topo, data = mites, family = binomial(link = "logit"))
# La fonction de lien «logit» est la fonction par défaut pour une régression logistique,
# ce qui signifie qu'il n'est pas nécessaire de l'indiquer avec l'argument «family»:
logit.reg <- glm(pa ~ WatrCont + Topo, data = mites, family = binomial)
summary(logit.reg)
```

### Défi 1

En utilisant le jeu de données `bacteria` (du paquet `MASS`), modélisez
la présence de *H. influenzae* en fonction du traitement (`trt`) et de
la semaine de test (`week`). Commencez avec un modèle complet et
réduisez-le jusqu'à obtenir le modèle le plus parcimonieux possible.

```{r, echo = FALSE, eval = TRUE, warning=FALSE}
library(MASS)
```
```{r, echo = TRUE, eval = TRUE}
data(bacteria)
str(bacteria)
```

**Solution**

```{r, echo = TRUE, eval = TRUE}
model.bact1 <- glm(y ~ trt * week, family = binomial('logit'), data = bacteria)
model.bact2 <- glm(y ~ trt + week, family = binomial('logit'), data = bacteria)
model.bact3 <- glm(y ~ week, family = binomial('logit'), data = bacteria)
anova(model.bact1, model.bact2, model.bact3, test = 'LRT')
```
En se basant sur ces résultats, on doit choisir le modèle 2
comme celui représentant le mieux le jeu de données.

## Interpréter la sortie d'une régression logistique

La sortie du modèle de régression logistique indique que les deux
variables explicatives (`WatrCont` et `Topo`) sont significatives, mais
comment interprète-on les coefficients estimés? Rappelez-vous que nous
avons effectué une transformation des valeurs prédites par le modèle
(*i.e.* la probabilité que Y = 1), alors il faut utiliser une fonction
inverse pour pouvoir interpréter correctement les résultats. On peut
utiliser la fonction exponentielle `exp` pour obtenir la cote de
probabilité pour chaque variable explicative.

```{r, echo = TRUE, eval = TRUE}
logit.reg
```

Pour obtenir les pentes, il faut utiliser la fonction exponentielle exp().
Ceci mettra les coefficients sur l'échelle des cotes. Mathématiquement,
ceci correspond à :  
**exp(model coefficients) = exp(log(μ / (1 - μ)) = u / (1 - μ)**.

C'est notre rapport de cotes !

```{r, echo = TRUE, eval = TRUE}
exp(logit.reg$coefficients[2])
```

Pour obtenir l'intervalle de confiance sur l'échelle des cotes :
```{r, echo = TRUE, eval = TRUE, message = FALSE}
exp(confint(logit.reg)[2,])
```

Prenez note que la cote pour une variable explicative est calculée
lorsque les autres variables sont gardées constantes. La topographie a
une cote de 8.09. Ceci signifie que la probabilité d'observer *Galumna*
sp. est 8.09 fois plus vraisemblable lorsque la topographie est de type
`hummock` plutôt que `blanket`.

Lorsque la cote est inférieure à 1, l'interprétation est un peu plus
compliquée. Si c'est le case, il faut prendre la valeur inverse de la
cote (*i.e.* 1 divisé par la cote) pour faciliter l'interprétation.
L'interprétation revient à dire comment l'observation d'un phénomène
est **MOINS** probable. Pour le contenu en eau du sol, la cote est de
0.984. L'inverse est 1 / 0.984 = 1.0159. Ceci signifie que
l'augmentation d'une unité en contenu en eau diminue la vraisemblance
d'observer la présence de *Galumna* sp. de 1.0159. On peut aussi
l'exprimer en pourcentage en soustrayant 1 à cette valeur : (1.0159 -
1) \* 100 = 1.59 %. Il est 1.59 % moins vraisemblable d'observer
*Galumna* sp. avec une augmentation d'une unité de contenu en eau. Pour
se convaincre qu'on fait la bonne interprétation, on peut représenter
graphiquement les résultats de la présence de *Galumna* sp. en fonction
du contenu en eau du sol. On voit qu'en moyenne la présence de
*Galumna* sp. est plus élevée lorsque le contenu en eau est faible.

![](images/galumna_pa.png){width="400"}

Lorsqu'un paramètre estimé est entre 0 et 1 sur l'échelle des cotes,
la relation entre la variable réponse et la variable explicative est
négative. Si la valeur est supérieure à 1, cela indique une relation
positive entre les variables. Si l'intervalle de confiance inclut la
valeur 1, la relation entre les variables n'est pas significative.
Rappelez-vous qu'une valeur de 1 sur l'échelle des cotes signifie que
la probabilité d'observer un phénomène Y est la même que celle de ne
pas observer ce phénomène (*i.e.* quand p = 0.5, 0.5/(1-0.5) = 1).

Pour obtenir une probabilité au lieu d'une cote pour chaque variable
explicative, il faut utiliser la fonction logit inverse :

logit^-1^ = 1/(1+1/exp(x))

où x est le paramètre à transformer de l'échelle log odds à l'échelle
de probabilité. Pour le modèle `logit.reg`, le paramètre estimé pour la
topographie est de 2.091 sur l'échelle log odds. Donc, la probabilité
est donnée par :

1/(1+1/exp(2.091)) = 0.89 ce qui équivaut à 1/(1+1/8.09). Rappelez-vous
que la valeur 8.09 est sur l'échelle des cotes. On a une probabilité de
0.89 d'observer *Galumna* sp. lorsque la topographie est de type
`hummock`.

Calculons cette valeur de cote sans utiliser la fonction exp():

On commence avec la valeur de cote pour la topographie du modèle logit.reg:  
**µ/ (1 - µ) = 8.09**

On réarrange pour isoler µ :  
**µ = 8.09(1 - µ) = 8.09 - 8.09µ**  
**8.09µ + µ = 8.09**  
**µ(8.09 + 1) = 8.09**  
**µ = 8.09 / (8.09 + 1)**  
**µ = 1 / (1 + (1 / 8.09)) = 0.89**

On obtient le même résultat sans utiliser la fonction logit inverse !

## Pouvoir prédictif et validation du modèle

Une façon simple et intuitive d'estimer le pouvoir explicatif d'un GLM
est de comparer la déviance du modèle à celle d'un modèle nul. La
déviance peut être vue comme une généralisation du concept de la somme
des carrés résiduelle lorsque le modèle est estimé par maximisation de
la vraisemblance (*i.e.* la méthode par laquelle on estime les
paramètres d'un GLM). Ceci nous permet de calculer un pseudo-R^2^, une
statistique similaire au R^2^ dans une régression des moindres carrés
(*i.e.* la méthode utilisée pour estimer les paramètres d'une
régression linéaire de base). Le modèle nul correspond à un modèle sans
variable explicative. Dans R, on l'indique de la façon suivante :
`null.model <- glm(Response.variable ~ 1, family = binomial)`. La forme
générique pour calculer un pseudo-R^2^ est :

Pseudo-R^2^ = (déviance du modèle nul -- déviance résiduelle) / déviance
résiduelle

où \«déviance du modèle nul\» est la déviance du modèle nul et
\«déviance résiduelle\» est la déviance résiduelle du modèle d'intérêt.
La différence est divisée par la déviance du modèle nul afin de
contraindre le pseudo-R^2^ entre 0 et 1.

```{r, echo = TRUE, eval = TRUE}
# Les déviances résiduelle et nulle sont déjà enregistrées dans un objet de type glm.
objects(logit.reg)
pseudoR2 <- (logit.reg$null.deviance - logit.reg$deviance) / logit.reg$null.deviance
pseudoR2
```
Les variables explicatives du modèle expliquent 46.6% de la variabilité
de la variable réponse.

Un pseudo-R^2^ de McFadden ajusté, qui pénalise pour le nombre de
prédicteurs, peut être calculé comme suit:

![](images/McFadden.PNG)

où **K** correspond au nombre supplémentaire de prédicteurs par rapport
au modèle nul.

La qualité d'ajustement des modèles de régression logistique peut être
exprimée par des variantes de statistiques pseudo-R^2^, telles que les
mesures de Maddala (1983) ou de Cragg et Uhler (1970).

Lorsqu'on parle de régressions logistiques, les valeurs faibles de **R^2^**
sont courantes.

La fonction R ```DescTools::PseudoR2()``` permet de calculer plusieurs pseudo-R^2^. En spécifiant ```which = all```, calculez toutes les statistiques en même temps.

```{r, echo = TRUE, eval = TRUE}
logit.reg <- glm(pa ~ WatrCont + Topo, 
                 data = mites, family = binomial(link = "logit"))
DescTools::PseudoR2(logit.reg, which = "all")
```


```{r, echo = FALSE, eval = FALSE}
### ENLEVÉ PARCE QUE LE PACKAGE binomTools A ÉTÉ RETIRÉ DU CRAN (à supprimer?)

Récemment, [Tjur
(2009)](http://www.tandfonline.com/doi/abs/10.1198/tast.2009.08210#.VFpKZYcc4ow)
a proposé une nouvelle statistique, le coefficient de discrimination
(*D*), afin d'évaluer le pouvoir prédictif d'une régression
logistique. Intuitivement, *D* évalue si la régression logistique peut
classer adéquatement chaque résultat comme un succès ou un échec.
Mathématiquement, c'est la différence entre la moyenne des valeurs
prédites des succès (*i.e.* Y = 1) et des échecs (*i.e.* Y = 0) :

*D = π~1~ - π~0~*

où *π~1~* est la moyenne attendue des probabilités
lorsqu'un événement est observé et *π~0~* est la
moyenne attendue des probabilités lorsqu'un événement n'est pas
observé. Une valeur de *D* près de 1 indique que le modèle accorde une
probabilité élevée d'observer un événement lorsque celui-ci a été
observé et une probabilité faible d'observer un événement lorsque
celui-ci n'a pas été observé. Une valeur de *D* près de 0 indique que
le modèle n'est pas utile pour distinguer entre les observations et les
«non-observations» d'un résultat.



# Le code suivant montre comment obtenir la valeur de *D* et comment représenter #visuellement les valeurs
de *π~1~* et *π~0~*.

install.packages("binomTools")
library("binomTools")
# La fonctions Rsq calcule indices d'ajustement
# dont le coefficient de discrimination.
# Pour plus d'information sur les autres indices, consultez Tjur (2009).
# Les histogrammes montrent la distribution des valeurs attendues lorsque le résultat est observé
# et non observé.
# Idéalement, le recouvrement entre les deux histogrammes doit être minimal.
fit <- Rsq(object = logit.reg)
fit
# R-square measures and the coefficient of discrimination, 'D':
#
#    R2mod     R2res     R2cor     D
#    0.5205221 0.5024101 0.5025676 0.5114661
#
# Number of binomial observations:  70
# Number of binary observation:  70
# Average group size:  1
plot(fit, which = "hist")


Pour évaluer l'ajustement (*i.e.* goodness-of-fit) d'une régression
logistique, les graphiques de diagnostic ne sont pas très utiles (voir
atelier 4). On utilise plutôt un [test de
Hosmer-Lemeshow](http://en.wikipedia.org/wiki/Hosmer-Lemeshow_test) pour
évaluer si un modèle est approprié ou non. Ce test sépare les valeurs
attendues (ordonnées de la plus faible à la plus grande) en groupes de
même taille. Dix groupes est généralement le nombre de groupes
recommandé. Pour chaque groupe, on compare les valeurs observées aux
valeurs attendues. Le test est similaire à un test de khi-carré avec G -
2 degrés de liberté (G est le nombre de groupes). Dans R, ce test est
disponible dans le paquet `binomTools` ou `vcdExtra`.

```{r, echo = TRUE, eval = FALSE}
fit <- Rsq(object = logit.reg)
HLtest(object = fit)
# La valeur de p est de 0.9051814. Donc, on ne rejète pas notre modèle.
# L'ajustement du modèle est bon.
```

### Défi 2

Évaluez l'ajustement et le pouvoir prédictif du modèle `model.bact2`.
Comment pouvez-vous améliorer le pouvoir prédictif du modèle ?

**Solution**

```{r, echo = TRUE, eval = TRUE}
null.d <- model.bact2$null.deviance
resid.d <- model.bact2$deviance
bact.pseudoR2 <- (null.d - resid.d) / null.d
bact.pseudoR2
```
```{r, echo = FALSE, eval = FALSE}
#ENLEVÉ parce que le package binomTools retiré du CRAN

library(binomTools)
HLtest(Rsq(model.bact2))
# Chi-square statistic:  7.812347  with  8  df
# P-value:  0.4520122
# L'ajustement est adéquat.
```
C'est très faible!

Le pouvoir prédictif pourrait être augmenté en incluant plus de
variables explicatives.

## Représentation graphique des résultats

Lorsque le modèle a été validé, il peut être utile de représenter les
résultats graphiquement afin de voir comment la variable est influencée
par les variables explicatives. Une façon de faire est de mettre à la
fois les valeurs observées et prédites de la variable réponse en
fonction d'une variable explicative sur un même graphique. Voici un
exemple avec le paquet `ggplot2`. Revoir [l'atelier 3](r_workshop3)
pour plus d'informations sur ce paquet.

```{r, echo = FALSE, eval = TRUE, warning = FALSE}
library(ggplot2)
```
```{r, echo = TRUE, eval = TRUE, fig.width = 7, fig.height = 7, fig.align = "center", warning = FALSE, message = FALSE}
ggplot(mites, aes(x = WatrCont, y = pa)) + geom_point() +
stat_smooth(method = "glm", family= "binomial", se = FALSE) + xlab("Water content") +
ylab("Probabilité de présence") +
ggtitle("Probabilité de présence de Galumna sp. en fonction du contenu en eau")
```